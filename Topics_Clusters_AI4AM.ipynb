{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2588af5e",
   "metadata": {},
   "source": [
    "### Ragas is a framework that helps you evaluate your Retrieval Augmented Generation (RAG) pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2208c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai==0.28.1\n",
    "#!pip install openai --upgrade\n",
    "#!pip install ragas\n",
    "#!pip install unstructured\n",
    "#!pip install langchain[all]\n",
    "#!pip install --upgrade langchain\n",
    "\n",
    "#!pip install playwright\n",
    "#!pip install -U selenium unstructured\n",
    "#!pip install --upgrade langchain langchain-community langchainhub langchain-openai langchain-chroma bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f82908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydantic==2.5\n",
    "#!pip install rapidocr-onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5324fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e13d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/oleg/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "#from langchain.chains import AnalyzeDocumentChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from utils import OPENAI_API_KEY\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY \n",
    "from llm_utils import load_pdf_documets\n",
    "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "#openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9417d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_community.document_loaders import SeleniumURLLoader,  DirectoryLoader, PyPDFLoader\n",
    "#from langchain.text_splitter import CharacterTextSplitter,  RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d2116d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/utils/utils.py:161: UserWarning: WARNING! top_p is not default parameter.\n",
      "                top_p was transferred to model_kwargs.\n",
      "                Please confirm that top_p is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1, top_p=0.2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a80fa6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_utills import *\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f73e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"AI4AM_topics3.json\", \"r+\") as f:\n",
    "    dict_topics = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35125c5",
   "metadata": {},
   "source": [
    "### Clustering topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad6eb404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Statistical Mechanics and Thermodynamics', 'Machine Learning and Data Science', 'Computational Methods and Simulations', 'Quantum Computing and Quantum Materials', 'Materials Characterization Techniques', 'Nanotechnology and Nanomaterials', 'Electrochemical and Energy Materials', 'Magnetic Materials and Properties', 'Chemical Reactions and Catalysis', 'Surface Science and Dynamics', 'Neuroscience and Brain Activity', 'Materials Informatics and Design', 'Advanced Manufacturing Techniques', 'Optoelectronics and Photonics'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "clustering_topics_prompt.partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "\n",
    "chain = clustering_topics_prompt | llm | parser \n",
    "# Cluster's dictionary\n",
    "cl_dict = chain.invoke({\"topics\": {k: v[\"description\"] for k,v in dict_topics.items()},\n",
    "                        \"N\": len(dict_topics.keys())//8 +1,\n",
    "                       \"L\": len(dict_topics)}\n",
    "                      )\n",
    "\n",
    "cl_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b712825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing topics: 48, All topics: 74, Clusters: 14\n",
      "Number of missing topics: 22, Clusters: 16\n",
      "Number of missing topics: 22, All topics: 100, Clusters: 16\n",
      "Number of missing topics: 5, Clusters: 22\n",
      "Number of missing topics: 5, All topics: 117, Clusters: 22\n",
      "Number of missing topics: 0, Clusters: 24\n"
     ]
    }
   ],
   "source": [
    "cl_topics = []\n",
    "for cl in cl_dict.keys():\n",
    "    cl_topics += [list(n.keys())[0] for n in cl_dict[cl]['nodes']] # All topics in all clusters\n",
    "\n",
    "    \n",
    "diff_topics = set(dict_topics).difference(set(cl_topics)) # Topics that are not any cluster\n",
    "#len(diff_topics)\n",
    "max_it = 4\n",
    "\n",
    "while len(diff_topics) and (max_it >0):\n",
    "    print(f\"Number of missing topics: {len(diff_topics)}, All topics: {len(cl_topics)}, Clusters: {len(cl_dict)}\")\n",
    "    # Clustering missing topics\n",
    "    \n",
    "    clustering_topics_add.partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "\n",
    "    chain = clustering_topics_add | llm | parser \n",
    "    # New cluster's dictionary\n",
    "    new_dict = chain.invoke({\"topics\": {k: v['description'] for k,v in dict_topics.items() if k in diff_topics},\n",
    "                        \"cluster\": {k: v['description'] for k,v in cl_dict.items()},\n",
    "                       }\n",
    "                      )\n",
    "    # Adding to the original cluster's dictionary\n",
    "    for cl,v in new_dict.items():\n",
    "        if cl not in cl_dict:\n",
    "            cl_dict[cl] = new_dict[cl]\n",
    "        else:\n",
    "            cl_dict[cl]['nodes'] += new_dict[cl]['nodes']\n",
    "            \n",
    "    cl_topics = []\n",
    "    for cl in cl_dict.keys():\n",
    "        cl_topics += [list(n.keys())[0] for n in cl_dict[cl]['nodes']] # All topics in all clusters\n",
    "        \n",
    "    diff_topics = set(dict_topics).difference(set(cl_topics)) # Topics that are not any cluster\n",
    "    print(f\"Number of missing topics: {len(diff_topics)}, Clusters: {len(cl_dict)}\")\n",
    "    max_it -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8354a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Statistical Mechanics and Thermodynamics', 'Machine Learning and Data Science', 'Computational Methods and Simulations', 'Quantum Computing and Quantum Materials', 'Materials Characterization Techniques', 'Nanotechnology and Nanomaterials', 'Electrochemical and Energy Materials', 'Magnetic Materials and Properties', 'Chemical Reactions and Catalysis', 'Surface Science and Dynamics', 'Neuroscience and Brain Activity', 'Materials Informatics and Design', 'Advanced Manufacturing Techniques', 'Optoelectronics and Photonics', 'High-Entropy Alloys', 'Point Defects', 'Semiconductors and Band Gap Properties', 'Diffusion and Ionic Conductivity', 'Oxide Materials and Electronics', 'Topological Properties', 'Materials Science', 'Metallurgy', 'Solubility and Hydrogen Bonding', 'Data Interoperability in Materials Science'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a40fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add the clusters nodes and edges\n",
    "for node in cl_dict.keys():\n",
    "    G.add_node(node, description =cl_dict[node]['description'])\n",
    "    if len(cl_dict[node]['nodes']):\n",
    "        for d in cl_dict[node]['nodes']:\n",
    "            n = list(d.keys())[0]\n",
    "            G.add_node(n, description =d[n])\n",
    "            G.add_edge(node, n)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ad70227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition documents nodes\n",
    "for t in dict_topics.keys():\n",
    "    for d in dict_topics[t]['metadata']:\n",
    "        n = d['source'].split('/')[-1].split('.')[0] # Name of the document\n",
    "        G.add_node(n,  description =\"pdf doc\")\n",
    "        G.add_edge(n, t)\n",
    "        G.add_edge(t, n)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfddd3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved as graph_AI4AM_topics_v1.gexf\n"
     ]
    }
   ],
   "source": [
    "# Save the graph as GEXF including edge attributes\n",
    "f_name = \"graph_AI4AM_topics_v1.gexf\"\n",
    "nx.write_gexf(G, f_name)\n",
    "\n",
    "print(f\"Graph saved as {f_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "223bdbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_document(cluster, name=\"pdf doc\"):\n",
    "    \n",
    "    # Find 1-step neighbors\n",
    "    one_step_successors = set(G.neighbors(cluster))\n",
    "\n",
    "    # Find 2-step neighbors\n",
    "    two_step_successors = set()\n",
    "    for neighbor in one_step_successors:\n",
    "        two_step_successors.update(set(G.neighbors(neighbor)))\n",
    "   \n",
    "    # Collect the 2-step successors along with the filtered descriptions\n",
    "    two_step_successors = [d for d in two_step_successors if  G.nodes[d]['description'] == name] # Only pdf docs\n",
    "\n",
    "    return two_step_successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5c96ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['90_AI4AM2024_Schleder_Gabriel_42',\n",
       " '77_AI4AM2024_Soljacic',\n",
       " '82_AI4AM2024_ghosh_aishwaryo_4',\n",
       " '74_AI4AM2024_Buitrago_Diaz_Juan_Camilo_79',\n",
       " '8_AI4AM2024_Pena_Corredor_Antonio_19']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_document('Materials Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68f91798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['72_AI4AM2024_Engelgardt_Dana_84',\n",
       " '80_AI4AM2024_Csanyi',\n",
       " '51_AI4AM2024_Malica_Cristiano_30',\n",
       " '20_AI4AM2024_Žugec_Ivan_55',\n",
       " '70_AI4AM2024_Persson_Gabriel_28',\n",
       " '11_AI4AM2024_Kruglov_Ivan_27',\n",
       " '2_AI4AM2024_palermo_vincenzo_63',\n",
       " '86_AI4AM2024_Garrido_Aldea_Jaime_85',\n",
       " '82_AI4AM2024_ghosh_aishwaryo_4',\n",
       " '56_AI4AM2024_Toher_Cormac_17',\n",
       " '87_AI4AM2024_Abio_Albert_88',\n",
       " '83_AI4AM2024_Delgado_Galindo_Pedro_Julian_87',\n",
       " '30_AI4AM2024_Barnard_Amanda_49',\n",
       " '5_AI4AM2024_Trinquet_Victor_77',\n",
       " '32_AI4AM2024_Joshi_Kavita_12',\n",
       " '42_AI4AM2024_Grzelczak_Marek_34',\n",
       " '40_AI4AM2024_Colnaghi_Timoteo_65',\n",
       " '89_AI4AM2024_Botti',\n",
       " '84_AI4AM2024_Carrasquilla',\n",
       " '6_AI4AM2024_Lazarev_Mikhail_80',\n",
       " '17_AI4AM2024_Riu_Vicente_Jordi_67',\n",
       " '67_AI4AM2024_Alcon_Isaac_3',\n",
       " '8_AI4AM2024_Pena_Corredor_Antonio_19',\n",
       " '41_AI4AM2024_Heras-Domingo_Javier_22',\n",
       " '90_AI4AM2024_Schleder_Gabriel_42',\n",
       " '48_AI4AM2024_Pozdnyakov_Sergey_15',\n",
       " '60_AI4AM2024_Marco_Moors_50',\n",
       " '64_AI4AM2024_Vozza_Mario_59',\n",
       " '45_AI4AM2024_Hakim_AMARA_8',\n",
       " '85_AI4AM2024_Reuter',\n",
       " '92_AI4AM2024_Kozinsky',\n",
       " '73_AI4AM2024_Forni_Tommaso_60',\n",
       " '66_AI4AM2024_Benaissa_Mohammed_62',\n",
       " '79_AI4AM2024_von_Lilienfeld',\n",
       " '15_AI4AM2024_Martin-Encinar_Luis_5',\n",
       " '7_AI4AM2024_Nair_Adithya_46',\n",
       " '35_AI4AM2024_Cheng',\n",
       " '81_AI4AM2024_Hippalgaonkar',\n",
       " '68_AI4AM2024_Sandholt_Hansen_William_26',\n",
       " '62_AI4AM2024_Andersson_Oskar_35',\n",
       " '43_AI4AM2024_Vignale_Giovanni_58',\n",
       " '33_AI4AM2024_Alducin',\n",
       " '47_AI4AM2024_Rossi_Antonio_68',\n",
       " '28_AI4AM2024_Mishchenko_Artem_13',\n",
       " '71_AI4AM2024_Lyngby_Peder_53',\n",
       " '49_AI4AM2024_Cao_Junhao_33',\n",
       " '91_AI4AM2024_Wenzel',\n",
       " '23_AI4AM2024_Cole_Ivan_10',\n",
       " '18_AI4AM2024_Parackal_Abhijith_S_82',\n",
       " '53_AI4AM2024_Brunin_Guillaume_69',\n",
       " '14_AI4AM2024_Tomut_Andrei_41',\n",
       " '13_AI4AM2024_Kaya_Onurcan_24',\n",
       " '59_AI4AM2024_Oikonomou_Ilias-Panagiotis_81',\n",
       " '19_AI4AM2024_Febrer_Pol_38',\n",
       " '31_AI4AM2024_Tyner_Alexander_18',\n",
       " '57_AI4AM2024_Maevskiy_Artem_70',\n",
       " '38_AI4AM2024_Polak_Elias_56',\n",
       " '10_AI4AM2024_Khatibi_Zahra_74',\n",
       " '9_AI4AM2024_Dale_Stephen_75',\n",
       " '29_AI4AM2024_Lian_Zan_20',\n",
       " '21_AI4AM2024_Lopez_Álvarez_Cibran_7',\n",
       " '88_AI4AM2024_Coxson_Adam_89',\n",
       " '27_AI4AM2024_Barnard',\n",
       " '1_AI4AM2024_Cisotto',\n",
       " '58_AI4AM2024_Siddiqui_Gohar_Ali_54',\n",
       " '26_AI4AM2024_Benitez_Colominas_Pol_9',\n",
       " '39_AI4AM2024_Hine_Nicholas_16',\n",
       " '24_AI4AM2024_Pereira_Luiz_Felipe_73',\n",
       " '36_AI4AM2024_Choudhary',\n",
       " '22_AI4AM2024_Kazeev_Nikita_78',\n",
       " '12_AI4AM2024_Siddiqui_Anas_23',\n",
       " '76_AI4AM2024_Seitsonen_Ari_Paavo_36',\n",
       " '75_AI4AM2024_Pathak_Swapneel_Amit_51',\n",
       " '4_AI4AM2024_Magdau_Ioan_Bogdan_39',\n",
       " '3_AI4AM2024_Shibaev_Egor_66',\n",
       " '50_AI4AM2024_Cuniberti',\n",
       " '69_AI4AM2024_Sharma_Kartikeya_72',\n",
       " '65_AI4AM2024_Garcia_Aguilar_Jose_Hugo_52',\n",
       " '77_AI4AM2024_Soljacic',\n",
       " '74_AI4AM2024_Buitrago_Diaz_Juan_Camilo_79',\n",
       " '61_AI4AM2024_Kara_Abdelkader_40',\n",
       " '34_AI4AM2024_Dalpian_Gustavo_14',\n",
       " '46_AI4AM2024_Ceto_Xavier_37',\n",
       " '25_AI4AM2024_ALHADA-LAHBABI_KEVIN_6',\n",
       " '44_AI4AM2024_Piaggi_Pablo_48',\n",
       " '37_AI4AM2024_Plodzien_Marcin_76',\n",
       " '63_AI4AM2024_Seoane_Juan_Jose__83',\n",
       " '54_AI4AM2024_Ustyuzhanin_Andrey_64',\n",
       " '55_AI4AM2024__Hoffmann_Petersen_Martin__25',\n",
       " '52_AI4AM2024_Hernandez_Bertran_Michael_Alejandro_32']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_document('Machine Learning and Data Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d7bdd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
