{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2588af5e",
   "metadata": {},
   "source": [
    "### Fine tune LLM embeedings model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2208c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai==0.28.1\n",
    "#!pip install openai --upgrade\n",
    "#!pip install ragas\n",
    "#!pip install unstructured\n",
    "#!pip install langchain[all]\n",
    "#!pip install --upgrade langchain\n",
    "\n",
    "#!pip install playwright\n",
    "#!pip install -U selenium unstructured\n",
    "#!pip install --upgrade langchain langchain-community langchainhub langchain-openai langchain-chroma bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d63c1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydantic==2.5\n",
    "#!pip install --upgrade --quiet  langchain_milvus\n",
    "#!pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3566c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf10af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install llama-index-embeddings-langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e13d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "#import openai\n",
    "#from langchain.chat_models import ChatOpenAI, ChatGooglePalm\n",
    "from utils import OPENAI_API_KEY\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] =  OPENAI_API_KEY\n",
    "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "#openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da0f4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59018bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (BertTokenizer, \n",
    "                          BertModel,\n",
    "                          BertForMaskedLM, \n",
    "                          Trainer, \n",
    "                          TrainingArguments, \n",
    "                          DataCollatorForLanguageModeling,\n",
    "                          DataCollatorForWholeWordMask,\n",
    "                          DataCollatorWithPadding\n",
    "                         )\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a449772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import SeleniumURLLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, NLTKTextSplitter\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "\n",
    "ai_model = \"gpt-3.5-turbo-0125\"\n",
    "ai_model = \"gpt-4o\"\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=ai_model, temperature=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ef0ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    context_utilization,\n",
    "    context_entity_recall,\n",
    "    context_relevancy,\n",
    "    answer_relevancy,\n",
    "    answer_correctness, \n",
    "    faithfulness,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "from datasets import Dataset \n",
    "\n",
    "from ragas.evaluation import evaluate\n",
    "import nest_asyncio\n",
    "#from ragas import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfcbe35",
   "metadata": {},
   "source": [
    "### Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "456d2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_url_documets(list_urls, tokens=500):\n",
    "    \n",
    "    # Load, chunk and index the contents of the blog.\n",
    "    loader_url =SeleniumURLLoader( list_urls)\n",
    "    docs = loader_url.load()\n",
    "    #text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\",\"\\n\"], chunk_size=500, chunk_overlap=50)\n",
    "    text_splitter = NLTKTextSplitter(chunk_size=tokens, chunk_overlap=50)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    \n",
    "    return splits, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90349841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1063, which is longer than the specified 500\n",
      "Created a chunk of size 539, which is longer than the specified 500\n",
      "Created a chunk of size 528, which is longer than the specified 500\n",
      "Created a chunk of size 577, which is longer than the specified 500\n",
      "Created a chunk of size 949, which is longer than the specified 500\n",
      "Created a chunk of size 722, which is longer than the specified 500\n",
      "Created a chunk of size 1304, which is longer than the specified 500\n",
      "Created a chunk of size 1227, which is longer than the specified 500\n",
      "Created a chunk of size 614, which is longer than the specified 500\n",
      "Created a chunk of size 638, which is longer than the specified 500\n",
      "Created a chunk of size 2175, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232 2\n"
     ]
    }
   ],
   "source": [
    "url_list = [\"https://www.nature.com/articles/s41524-023-01062-z\",\n",
    "            \"https://www.nature.com/articles/s41699-023-00369-1\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/tree/main/docs/CONSTRUCTOR-MOCK.md\"\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/CONSTRUCTOR.md\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/DATA.md\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/ENVIRONMENT.md\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/GENERATING-CONSTRUCTOR.md\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/GENERATING-MOCK.md\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/PILOT.md\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/SPARSE-PAPER.md\"\n",
    "          #  \"https://www.nature.com/articles/s41377-024-01407-3\",\n",
    "          #  \"https://www.nature.com/articles/s41565-023-01407-1\",\n",
    "          #  \"https://www.nature.com/articles/s41699-023-00369-1\",\n",
    "           ]\n",
    "                               \n",
    "chunks, documents = load_url_documets(url_list)\n",
    "print(len(chunks), len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6138ce6",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82721fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "No sentence-transformers model found with name ./results512a/checkpoint-1000. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./results512a/checkpoint-1000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./results512a/checkpoint-1000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a tokenizer specific to BAAI/bge-base-en-v1.5\n",
    "tokenizer = BertTokenizer.from_pretrained('BAAI/bge-base-en-v1.5')\n",
    "tokenizer.tokenize_chinese_chars = False\n",
    "\n",
    "# Load the BAAI/bge-base-en-v1.5 model \n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "hf_bge = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "model = BertModel.from_pretrained('BAAI/bge-base-en-v1.5')\n",
    "model.eval() # set the model in evaluation mode\n",
    "\n",
    "#### LOAD Fine tuning model\n",
    "\n",
    "# Load the model from the checkpoint directory\n",
    "model_name ='./results512a/checkpoint-1000'\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "hf_fine_tuned = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "model_fm = BertModel.from_pretrained('./results512a/checkpoint-1000')\n",
    "model_fm.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d9b80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ground_true = pd.read_csv(\"./data/data_rag/QA_ai4mat_2articles.csv\")\n",
    "\n",
    "questions = df_ground_true['question'].values.tolist()\n",
    "answers = df_ground_true['answer'].values.tolist()\n",
    "\n",
    "name = \"compare2embedding_model\"\n",
    "_df = pd.read_csv(f\"data/data_rag/qa_dict_{name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c114771f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question', 'answer_original_model', 'answer_FineTuned_model'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a18a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    " #  answer_relevancy, \n",
    "   faithfulness,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    context_entity_recall,\n",
    "    context_relevancy,\n",
    "    context_utilization,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c4742",
   "metadata": {},
   "source": [
    "#### Embedding model BAAI/bge-base-en-v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2190c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeeding(chunks, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Get embeddings for a list of chunks\n",
    "    \"\"\"\n",
    "    \n",
    "    texts = [t.page_content for t in chunks]\n",
    "    \n",
    "    emb = emb_texts(texts, model, tokenizer)\n",
    "\n",
    "    return emb\n",
    "\n",
    "def emb_texts(texts, model, tokenizer):   \n",
    "    \n",
    "    \"\"\"\n",
    "    Get embeddings for a list of texts\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval() # set the model in evaluation mode\n",
    "    # Tokenize the input texts\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # Get the embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # The last hidden state is used as embeddings\n",
    "        embeddings = outputs.last_hidden_state\n",
    "        # Pooled output is the mean of the last hidden state\n",
    "        pooled_emb = outputs.pooler_output.numpy()\n",
    "\n",
    "    return pooled_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b56d6413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_texts([\"What is DFS?\"], model, tokenizer).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361466bc",
   "metadata": {},
   "source": [
    "### 1. Create MilVus index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "641aab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pymilvus import MilvusClient\n",
    "\n",
    "milvus_client = MilvusClient(\"./milvus_demo.db\")\n",
    "\n",
    "collection_name = \"collection_ai4mat_bge_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb3508d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = get_embeeding(chunks, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef340a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63a80fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    dimension=len(emb[0]),\n",
    "    metric_type=\"IP\",  # Inner product distance\n",
    "    consistency_level=\"Strong\",  # Strong consistency level\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ba966a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings: 100%|█████████████████| 232/232 [00:00<00:00, 72294.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'insert_count': 232,\n",
       " 'ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231],\n",
       " 'cost': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for i, line in enumerate(tqdm(chunks, desc=\"Creating embeddings\")):\n",
    "    data.append({\"id\": i, \"vector\": emb[i], \"text\": chunks[i].page_content, })\n",
    "\n",
    "milvus_client.insert(collection_name=collection_name, data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48322d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_context(\n",
    "                question, \n",
    "                vecstore, \n",
    "                collection_name, \n",
    "                embedding, \n",
    "                top_k=10,\n",
    "                verbose=False,\n",
    "               ):\n",
    "    #print(embedding(q).shape)\n",
    "    \n",
    "    search_res = vecstore.search(\n",
    "         collection_name=collection_name,\n",
    "         data=[\n",
    "              embedding(question)\n",
    "              ],  # Use the `emb_texts` function to convert the question to an embedding vector\n",
    "         limit=top_k,  # Return top k results\n",
    "         search_params={\"metric_type\": \"IP\", \"params\": {}},  # Inner product distance\n",
    "         output_fields=[\"text\"],  # Return the text field\n",
    "             )\n",
    "\n",
    "    retrieved_lines_with_distances = [\n",
    "    (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n",
    "                                     ]\n",
    "    if verbose:\n",
    "        print(\"Retrieved lines with distances:\")\n",
    "        for line, distance in retrieved_lines_with_distances:\n",
    "            print(f\"- {line}\")\n",
    "            print(f\"  Distance: {distance}\")\n",
    "            print()\n",
    "         \n",
    "    \n",
    "    #context = \"\\n\".join(\n",
    "    #[line for (line, dist) in retrieved_lines_with_distances]\n",
    "    #      )\n",
    "    \n",
    "    context = [line for (line, dist) in retrieved_lines_with_distances]\n",
    "    \n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04a76eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = lambda q: emb_texts([q], model, tokenizer)[0]\n",
    "collection_name = \"collection_ai4mat_bge_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8db9801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "\n",
    "for q in questions:\n",
    "    context = get_context(q[2:], milvus_client, collection_name, embedding, top_k=10)\n",
    "    contexts.append(context)\n",
    "    \n",
    "#context = get_context(q, milvus_client, collection_name, embedding, verbose=verbose)\n",
    "\n",
    "data_samples = {'question': questions, \n",
    "           'ground_truth': answers,\n",
    "           \"contexts\": contexts,\n",
    "          \"answer\": _df[\"answer_original_model\"].values.tolist()\n",
    "          }\n",
    "dataset1 = Dataset.from_dict(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99f46d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd55df8d55474cde9207aa8ef049ae8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No statements were generated from the answer.\n",
      "No statements were generated from the answer.\n",
      "No statements were generated from the answer.\n",
      "No statements were generated from the answer.\n",
      "No statements were generated from the answer.\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "#query_engine_bge = build_query_engine(hf_bge, documents)\n",
    "result1 = evaluate(dataset1, metrics, llm=llm,  raise_exceptions=False, embeddings=hf_bge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6002106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.2450, 'context_precision': 0.0476, 'context_recall': 0.1095, 'context_entity_recall': 0.0088, 'context_relevancy': 0.0548, 'context_utilization': 0.0190}\n"
     ]
    }
   ],
   "source": [
    "print( result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d5d05eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.5310, 'context_precision': 0.8262, 'context_recall': 0.5643, 'context_entity_recall': 0.0388, 'context_relevancy': 0.0621, 'context_utilization': 0.8214}\n"
     ]
    }
   ],
   "source": [
    "print( result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6ee0a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.5549, 'context_precision': 0.8024, 'context_recall': 0.5429}\n"
     ]
    }
   ],
   "source": [
    "print( result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "11bfb581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.5704, 'context_precision': 0.7617, 'context_recall': 0.6714}\n"
     ]
    }
   ],
   "source": [
    "print( result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "889487d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>* Which materials are in the dataset?</td>\n",
       "      <td>The materials in the dataset include MoS2, WSe...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>The materials in the dataset include TMDCs (tr...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* How many structures are there in the dataset?</td>\n",
       "      <td>The dataset contains a total of 14,866 structu...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>There are 14,866 structures in the dataset.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936735</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* How to obtain the dataset?</td>\n",
       "      <td>The datasets analyzed in the study can be obta...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>To obtain the dataset of defect configurations...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>* What is the dataset license?</td>\n",
       "      <td>The dataset is licensed under a Creative Commo...</td>\n",
       "      <td>[Supplementary information\\n\\nSupplementary Ma...</td>\n",
       "      <td>The dataset license is not specified in the pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.941518</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>* What is the data format?</td>\n",
       "      <td>The data format of the dataset is in CSV forma...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>The data format is structured and organized, c...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>* How to read the dataset?</td>\n",
       "      <td>To access and read the dataset, you can visit ...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>To read the dataset, one must first understand...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>* How to browse the dataset?</td>\n",
       "      <td>The dataset can be browsed and explored by dow...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>To browse the dataset, you can utilize tools s...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>* Can I work with the dataset without Python?</td>\n",
       "      <td>Yes, you can work with the dataset without Pyt...</td>\n",
       "      <td>[The same rationale can be used to structure t...</td>\n",
       "      <td>No, you cannot work with the dataset without P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.906041</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>* How to obtain the raw VASP files?</td>\n",
       "      <td>To obtain the raw VASP files, follow these ste...</td>\n",
       "      <td>[1a).\\n\\nThere are hundreds of existing 2D mat...</td>\n",
       "      <td>To obtain the raw VASP files, you can perform ...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.797222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>* What were the settings used for the DFT comp...</td>\n",
       "      <td>The settings used for the DFT computations inc...</td>\n",
       "      <td>[The availability of such high-density defects...</td>\n",
       "      <td>The settings used for the DFT computations wer...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>* How well the DFT calculations correspond to ...</td>\n",
       "      <td>The provided context does not specifically add...</td>\n",
       "      <td>[The availability of such high-density defects...</td>\n",
       "      <td>The DFT calculations are generally known to pr...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>* How to cite the dataset?</td>\n",
       "      <td>To cite the dataset, you can use the provided ...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>To cite the dataset, you can reference the ori...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>* What was the procedure for SRGNN quality eva...</td>\n",
       "      <td>The procedure for SRGNN quality evaluation inv...</td>\n",
       "      <td>[The performance values are presented in Table...</td>\n",
       "      <td>The procedure for SRGNN quality evaluation inv...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.771379</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>* How is SRGNN different from the baselines?</td>\n",
       "      <td>SRGNN differs from the baseline models by inco...</td>\n",
       "      <td>[We compare the performance of our sparse repr...</td>\n",
       "      <td>SRGNN is different from the baselines in that ...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.905556</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>* What are the limitations of SRGNN?</td>\n",
       "      <td>The limitations of SRGNN are not explicitly me...</td>\n",
       "      <td>[In this spirit, a large number of computation...</td>\n",
       "      <td>The limitations of SRGNN (Structural Relation ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>* What is the core idea of SRGNN?</td>\n",
       "      <td>The core idea of SRGNN is to enhance the predi...</td>\n",
       "      <td>[As a future direction, in case generalization...</td>\n",
       "      <td>The core idea of SRGNN (Structural Relation Gr...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>* How to run the code?</td>\n",
       "      <td>To run the code based on the provided context,...</td>\n",
       "      <td>[The performance values are presented in Table...</td>\n",
       "      <td>To run the code provided in the context, you w...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>* Which frameworks were used for SRGNN impleme...</td>\n",
       "      <td>The SRGNN model was implemented using the PyTo...</td>\n",
       "      <td>[Since the materials we considered are normal ...</td>\n",
       "      <td>The frameworks used for SRGNN implementation w...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946781</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>* Can SRGNN be developed on a CPU, not a GPU?</td>\n",
       "      <td>Yes, SRGNN can be developed and trained on a C...</td>\n",
       "      <td>[Klicpera et al.14,17 (GemNet) redresses an im...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.678730</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>* What is the code license?</td>\n",
       "      <td>The code used for the SRGNN implementation is ...</td>\n",
       "      <td>[Supplementary information\\n\\nSupplementary Ma...</td>\n",
       "      <td>The code license for the provided context is n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>* How to cite the code?</td>\n",
       "      <td>To cite the code for the SRGNN model, you can ...</td>\n",
       "      <td>[The datasets as designed could provide traini...</td>\n",
       "      <td>To cite the code mentioned in the context prov...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.420635</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>* Which materials has the SRGNN been trained on?</td>\n",
       "      <td>The SRGNN has been trained on a dataset contai...</td>\n",
       "      <td>[Since the materials we considered are normal ...</td>\n",
       "      <td>The SRGNN (Symmetry-Resolved Graph Neural Netw...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.651871</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>* Which materials can the SRGNN be trained on?</td>\n",
       "      <td>The SRGNN can be trained on a variety of atomi...</td>\n",
       "      <td>[Since the materials we considered are normal ...</td>\n",
       "      <td>The SRGNN (Structure-Property Relationship Gra...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.970486</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>* Which defect types can the SRGNN be trained on?</td>\n",
       "      <td>SRGNN can be trained on various defect types p...</td>\n",
       "      <td>[Since the materials we considered are normal ...</td>\n",
       "      <td>The SRGNN (Structural Reconstruction Graph Neu...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.772619</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>* How many structures are needed for SRGNN tra...</td>\n",
       "      <td>SRGNN typically requires a dataset containing ...</td>\n",
       "      <td>[Our studies demonstrate that the prediction e...</td>\n",
       "      <td>The number of structures needed for SRGNN trai...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952629</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>* Can SRGNN handle 3D materials?</td>\n",
       "      <td>SRGNN is specifically designed and optimized f...</td>\n",
       "      <td>[As a future direction, in case generalization...</td>\n",
       "      <td>I don't know if SRGNN can handle 3D materials ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>* How much computational resources does SRGNN ...</td>\n",
       "      <td>Training a Sparse Representation Graph Neural ...</td>\n",
       "      <td>[Our studies demonstrate that the prediction e...</td>\n",
       "      <td>SRGNN (Structure-Property Relationship Graph N...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>* What is the inference speed of a SRGNN?</td>\n",
       "      <td>The inference speed of SRGNN, once trained, ca...</td>\n",
       "      <td>[Full size table\\n\\nIn terms of computation ti...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>* Which properties can be predicted using SRGNN?</td>\n",
       "      <td>Formation energy per site and HOMO–LUMO gap. T...</td>\n",
       "      <td>[In this spirit, a large number of computation...</td>\n",
       "      <td>The properties that can be predicted using SRG...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.961735</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>* What was the quality of SRGNN for each prope...</td>\n",
       "      <td>The quality of SRGNN for predicting properties...</td>\n",
       "      <td>[The performance values are presented in Table...</td>\n",
       "      <td>The quality of SRGNN for each property and mat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>* Can pre-trained SRGNN be used out-of-the-box?</td>\n",
       "      <td>Yes, a pre-trained SRGNN model can be used out...</td>\n",
       "      <td>[The model is trained with ordinary backpropag...</td>\n",
       "      <td>No, pre-trained SRGNN (Structural Relation Gra...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702778</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>* How well do SRGNN results correspond to expe...</td>\n",
       "      <td>The correspondence between SRGNN results and e...</td>\n",
       "      <td>[Our studies demonstrate that the prediction e...</td>\n",
       "      <td>Based on the provided context, there is no spe...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883532</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>* Can I use SRGNN in place of DFT?</td>\n",
       "      <td>No, SRGNN can provide accurate predictions for...</td>\n",
       "      <td>[A similar descriptor-based approach is used i...</td>\n",
       "      <td>No, you cannot use SRGNN (Structure-Property R...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.906041</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>* How can I use SRGNN to find materials for so...</td>\n",
       "      <td>SRGNN can be used to predict properties of mat...</td>\n",
       "      <td>[In this spirit, a large number of computation...</td>\n",
       "      <td>You can use SRGNN (Structure-Property Relation...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.644898</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>* Is SRGNN patented?</td>\n",
       "      <td>The patent status of SRGNN was not specified i...</td>\n",
       "      <td>[Klicpera et al.14,17 (GemNet) redresses an im...</td>\n",
       "      <td>I don't know if SRGNN is patented.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0               * Which materials are in the dataset?   \n",
       "1     * How many structures are there in the dataset?   \n",
       "2                        * How to obtain the dataset?   \n",
       "3                      * What is the dataset license?   \n",
       "4                          * What is the data format?   \n",
       "5                          * How to read the dataset?   \n",
       "6                        * How to browse the dataset?   \n",
       "7       * Can I work with the dataset without Python?   \n",
       "8                 * How to obtain the raw VASP files?   \n",
       "9   * What were the settings used for the DFT comp...   \n",
       "10  * How well the DFT calculations correspond to ...   \n",
       "11                         * How to cite the dataset?   \n",
       "12  * What was the procedure for SRGNN quality eva...   \n",
       "13       * How is SRGNN different from the baselines?   \n",
       "14               * What are the limitations of SRGNN?   \n",
       "15                  * What is the core idea of SRGNN?   \n",
       "16                             * How to run the code?   \n",
       "17  * Which frameworks were used for SRGNN impleme...   \n",
       "18      * Can SRGNN be developed on a CPU, not a GPU?   \n",
       "19                        * What is the code license?   \n",
       "20                            * How to cite the code?   \n",
       "21   * Which materials has the SRGNN been trained on?   \n",
       "22     * Which materials can the SRGNN be trained on?   \n",
       "23  * Which defect types can the SRGNN be trained on?   \n",
       "24  * How many structures are needed for SRGNN tra...   \n",
       "25                   * Can SRGNN handle 3D materials?   \n",
       "26  * How much computational resources does SRGNN ...   \n",
       "27          * What is the inference speed of a SRGNN?   \n",
       "28   * Which properties can be predicted using SRGNN?   \n",
       "29  * What was the quality of SRGNN for each prope...   \n",
       "30    * Can pre-trained SRGNN be used out-of-the-box?   \n",
       "31  * How well do SRGNN results correspond to expe...   \n",
       "32                 * Can I use SRGNN in place of DFT?   \n",
       "33  * How can I use SRGNN to find materials for so...   \n",
       "34                               * Is SRGNN patented?   \n",
       "\n",
       "                                         ground_truth  \\\n",
       "0   The materials in the dataset include MoS2, WSe...   \n",
       "1   The dataset contains a total of 14,866 structu...   \n",
       "2   The datasets analyzed in the study can be obta...   \n",
       "3   The dataset is licensed under a Creative Commo...   \n",
       "4   The data format of the dataset is in CSV forma...   \n",
       "5   To access and read the dataset, you can visit ...   \n",
       "6   The dataset can be browsed and explored by dow...   \n",
       "7   Yes, you can work with the dataset without Pyt...   \n",
       "8   To obtain the raw VASP files, follow these ste...   \n",
       "9   The settings used for the DFT computations inc...   \n",
       "10  The provided context does not specifically add...   \n",
       "11  To cite the dataset, you can use the provided ...   \n",
       "12  The procedure for SRGNN quality evaluation inv...   \n",
       "13  SRGNN differs from the baseline models by inco...   \n",
       "14  The limitations of SRGNN are not explicitly me...   \n",
       "15  The core idea of SRGNN is to enhance the predi...   \n",
       "16  To run the code based on the provided context,...   \n",
       "17  The SRGNN model was implemented using the PyTo...   \n",
       "18  Yes, SRGNN can be developed and trained on a C...   \n",
       "19  The code used for the SRGNN implementation is ...   \n",
       "20  To cite the code for the SRGNN model, you can ...   \n",
       "21  The SRGNN has been trained on a dataset contai...   \n",
       "22  The SRGNN can be trained on a variety of atomi...   \n",
       "23  SRGNN can be trained on various defect types p...   \n",
       "24  SRGNN typically requires a dataset containing ...   \n",
       "25  SRGNN is specifically designed and optimized f...   \n",
       "26  Training a Sparse Representation Graph Neural ...   \n",
       "27  The inference speed of SRGNN, once trained, ca...   \n",
       "28  Formation energy per site and HOMO–LUMO gap. T...   \n",
       "29  The quality of SRGNN for predicting properties...   \n",
       "30  Yes, a pre-trained SRGNN model can be used out...   \n",
       "31  The correspondence between SRGNN results and e...   \n",
       "32  No, SRGNN can provide accurate predictions for...   \n",
       "33  SRGNN can be used to predict properties of mat...   \n",
       "34  The patent status of SRGNN was not specified i...   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [a The space of defects in 2D materials and b ...   \n",
       "1   [a The space of defects in 2D materials and b ...   \n",
       "2   [a The space of defects in 2D materials and b ...   \n",
       "3   [Supplementary information\\n\\nSupplementary Ma...   \n",
       "4   [a The space of defects in 2D materials and b ...   \n",
       "5   [a The space of defects in 2D materials and b ...   \n",
       "6   [a The space of defects in 2D materials and b ...   \n",
       "7   [The same rationale can be used to structure t...   \n",
       "8   [1a).\\n\\nThere are hundreds of existing 2D mat...   \n",
       "9   [The availability of such high-density defects...   \n",
       "10  [The availability of such high-density defects...   \n",
       "11  [a The space of defects in 2D materials and b ...   \n",
       "12  [The performance values are presented in Table...   \n",
       "13  [We compare the performance of our sparse repr...   \n",
       "14  [In this spirit, a large number of computation...   \n",
       "15  [As a future direction, in case generalization...   \n",
       "16  [The performance values are presented in Table...   \n",
       "17  [Since the materials we considered are normal ...   \n",
       "18  [Klicpera et al.14,17 (GemNet) redresses an im...   \n",
       "19  [Supplementary information\\n\\nSupplementary Ma...   \n",
       "20  [The datasets as designed could provide traini...   \n",
       "21  [Since the materials we considered are normal ...   \n",
       "22  [Since the materials we considered are normal ...   \n",
       "23  [Since the materials we considered are normal ...   \n",
       "24  [Our studies demonstrate that the prediction e...   \n",
       "25  [As a future direction, in case generalization...   \n",
       "26  [Our studies demonstrate that the prediction e...   \n",
       "27  [Full size table\\n\\nIn terms of computation ti...   \n",
       "28  [In this spirit, a large number of computation...   \n",
       "29  [The performance values are presented in Table...   \n",
       "30  [The model is trained with ordinary backpropag...   \n",
       "31  [Our studies demonstrate that the prediction e...   \n",
       "32  [A similar descriptor-based approach is used i...   \n",
       "33  [In this spirit, a large number of computation...   \n",
       "34  [Klicpera et al.14,17 (GemNet) redresses an im...   \n",
       "\n",
       "                                               answer  faithfulness  \\\n",
       "0   The materials in the dataset include TMDCs (tr...      1.000000   \n",
       "1         There are 14,866 structures in the dataset.      0.000000   \n",
       "2   To obtain the dataset of defect configurations...      0.750000   \n",
       "3   The dataset license is not specified in the pr...           NaN   \n",
       "4   The data format is structured and organized, c...      0.750000   \n",
       "5   To read the dataset, one must first understand...      0.600000   \n",
       "6   To browse the dataset, you can utilize tools s...      1.000000   \n",
       "7   No, you cannot work with the dataset without P...           NaN   \n",
       "8   To obtain the raw VASP files, you can perform ...      0.750000   \n",
       "9   The settings used for the DFT computations wer...      0.333333   \n",
       "10  The DFT calculations are generally known to pr...      0.800000   \n",
       "11  To cite the dataset, you can reference the ori...      1.000000   \n",
       "12  The procedure for SRGNN quality evaluation inv...      0.666667   \n",
       "13  SRGNN is different from the baselines in that ...      0.500000   \n",
       "14  The limitations of SRGNN (Structural Relation ...           NaN   \n",
       "15  The core idea of SRGNN (Structural Relation Gr...      1.000000   \n",
       "16  To run the code provided in the context, you w...      0.000000   \n",
       "17  The frameworks used for SRGNN implementation w...      0.000000   \n",
       "18                                      I don't know.           NaN   \n",
       "19  The code license for the provided context is n...           NaN   \n",
       "20  To cite the code mentioned in the context prov...      0.666667   \n",
       "21  The SRGNN (Symmetry-Resolved Graph Neural Netw...      0.000000   \n",
       "22  The SRGNN (Structure-Property Relationship Gra...      0.666667   \n",
       "23  The SRGNN (Structural Reconstruction Graph Neu...      0.500000   \n",
       "24  The number of structures needed for SRGNN trai...      0.000000   \n",
       "25  I don't know if SRGNN can handle 3D materials ...           NaN   \n",
       "26  SRGNN (Structure-Property Relationship Graph N...      0.000000   \n",
       "27                                      I don't know.      1.000000   \n",
       "28  The properties that can be predicted using SRG...      0.750000   \n",
       "29  The quality of SRGNN for each property and mat...           NaN   \n",
       "30  No, pre-trained SRGNN (Structural Relation Gra...      1.000000   \n",
       "31  Based on the provided context, there is no spe...      0.000000   \n",
       "32  No, you cannot use SRGNN (Structure-Property R...      0.666667   \n",
       "33  You can use SRGNN (Structure-Property Relation...      1.000000   \n",
       "34                 I don't know if SRGNN is patented.           NaN   \n",
       "\n",
       "    context_precision  context_recall  \n",
       "0            1.000000        1.000000  \n",
       "1            0.936735        1.000000  \n",
       "2            0.988889        1.000000  \n",
       "3            0.941518        1.000000  \n",
       "4            1.000000        1.000000  \n",
       "5            1.000000        1.000000  \n",
       "6            1.000000        1.000000  \n",
       "7            0.906041        1.000000  \n",
       "8            0.797222        0.000000  \n",
       "9            0.988889        0.333333  \n",
       "10           0.000000        0.333333  \n",
       "11           0.583333        1.000000  \n",
       "12           0.771379        1.000000  \n",
       "13           0.905556        0.333333  \n",
       "14           0.000000        1.000000  \n",
       "15           0.325000        0.500000  \n",
       "16           1.000000        0.333333  \n",
       "17           0.946781        0.500000  \n",
       "18           0.678730        0.666667  \n",
       "19           0.916667        0.000000  \n",
       "20           0.420635        0.000000  \n",
       "21           0.651871        0.500000  \n",
       "22           0.970486        1.000000  \n",
       "23           0.772619        0.000000  \n",
       "24           0.952629        0.500000  \n",
       "25           1.000000        1.000000  \n",
       "26           0.827381        1.000000  \n",
       "27           0.278571        0.500000  \n",
       "28           0.961735        0.000000  \n",
       "29           1.000000        1.000000  \n",
       "30           0.702778        1.000000  \n",
       "31           0.883532        0.000000  \n",
       "32           0.906041        1.000000  \n",
       "33           0.644898        1.000000  \n",
       "34           0.000000        1.000000  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df9455e",
   "metadata": {},
   "source": [
    "#### Using Fine-tunined BAAI/bge-base-en-v1.5 as embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3303e6",
   "metadata": {},
   "source": [
    "####  Create MilVus index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70d7719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pymilvus import MilvusClient\n",
    "\n",
    "milvus_client = MilvusClient(\"./milvus_demo.db\")\n",
    "\n",
    "collection_name = \"collection_ai4mat_bge_base_fine_tuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67dc098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = get_embeeding(chunks, model_fm, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9950dc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 768)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9dd2e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    dimension=len(emb[0]),\n",
    "    metric_type=\"IP\",  # Inner product distance\n",
    "    consistency_level=\"Strong\",  # Strong consistency level\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e22a93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings: 100%|████████████████| 232/232 [00:00<00:00, 409200.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'insert_count': 232,\n",
       " 'ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231],\n",
       " 'cost': 0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for i, line in enumerate(tqdm(chunks, desc=\"Creating embeddings\")):\n",
    "    data.append({\"id\": i, \"vector\": emb[i], \"text\": chunks[i].page_content, })\n",
    "\n",
    "milvus_client.insert(collection_name=collection_name, data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b2e35d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = lambda q: emb_texts([q], model_fm, tokenizer)[0]\n",
    "collection_name = \"collection_ai4mat_bge_base_fine_tuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5de9a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "\n",
    "for q in questions:\n",
    "    context = get_context(q[2:], milvus_client, collection_name, embedding, top_k=10)\n",
    "    contexts.append(context)\n",
    "    \n",
    "\n",
    "data_samples = {'question': questions, \n",
    "           'ground_truth': answers,\n",
    "           \"contexts\": contexts,\n",
    "          \"answer\": _df[\"answer_FineTuned_model\"].values.tolist()\n",
    "          }\n",
    "dataset2 = Dataset.from_dict(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1593c790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in threading.excepthook:\n",
      "Exception ignored in thread started by: <bound method Thread._bootstrap of <Runner(Thread-34, stopped 140580923373248)>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/oleg/miniconda3/envs/llm/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/oleg/miniconda3/envs/llm/lib/python3.10/threading.py\", line 1018, in _bootstrap_inner\n",
      "    self._invoke_excepthook(self)\n",
      "  File \"/home/oleg/miniconda3/envs/llm/lib/python3.10/threading.py\", line 1336, in invoke_excepthook\n",
      "    local_print(\"Exception in threading.excepthook:\",\n",
      "  File \"/home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages/ipykernel/iostream.py\", line 559, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages/ipykernel/iostream.py\", line 251, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages/ipykernel/iostream.py\", line 559, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages/ipykernel/iostream.py\", line 251, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b4c0bcb78e42238f2b989aeaa20b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No statements were generated from the answer.\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "result2 = evaluate(dataset2, metrics, llm=llm,  raise_exceptions=False, embeddings=hf_fine_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0094e6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned BGE model {'faithfulness': 0.5406, 'context_precision': 0.0721, 'context_recall': 0.2238, 'context_entity_recall': 0.0759, 'context_relevancy': 0.0327, 'context_utilization': 0.0606}\n",
      "Base BGE model {'faithfulness': 0.2450, 'context_precision': 0.0476, 'context_recall': 0.1095, 'context_entity_recall': 0.0088, 'context_relevancy': 0.0548, 'context_utilization': 0.0190}\n"
     ]
    }
   ],
   "source": [
    "print(\"Fine-tuned BGE model\",result2)\n",
    "print(\"Base BGE model\",result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbfc3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(result, name=None):\n",
    "    print(name)\n",
    "    keys = []\n",
    "    values = []\n",
    "    for k,v in result.items():\n",
    "        print(k,v)\n",
    "        keys.append(k)\n",
    "        values.append(v)\n",
    "    print()\n",
    "    return keys, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1fcf2c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base BGE model\n",
      "faithfulness 0.24500000000000002\n",
      "context_precision 0.04761904761428571\n",
      "context_recall 0.10952380952380951\n",
      "context_entity_recall 0.008843537401198575\n",
      "context_relevancy 0.05476469632952113\n",
      "context_utilization 0.019047619045714285\n",
      "\n",
      "Fine-tuned BGE model\n",
      "faithfulness 0.5405578898225957\n",
      "context_precision 0.07207482992798639\n",
      "context_recall 0.2238095238095238\n",
      "context_entity_recall 0.07586373907972258\n",
      "context_relevancy 0.03272856061499737\n",
      "context_utilization 0.06064625850055782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key, v_m1 = print_metrics(result1, \"Base BGE model\")\n",
    "key, v_m2 = print_metrics(result2, \"Fine-tuned BGE model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ef2f57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>Base BGE model</th>\n",
       "      <th>Fine-tuned BGE model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.540558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>context_precision</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.072075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>0.223810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context_entity_recall</td>\n",
       "      <td>0.008844</td>\n",
       "      <td>0.075864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>context_relevancy</td>\n",
       "      <td>0.054765</td>\n",
       "      <td>0.032729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>context_utilization</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.060646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  metric  Base BGE model  Fine-tuned BGE model\n",
       "0           faithfulness        0.245000              0.540558\n",
       "1      context_precision        0.047619              0.072075\n",
       "2         context_recall        0.109524              0.223810\n",
       "3  context_entity_recall        0.008844              0.075864\n",
       "4      context_relevancy        0.054765              0.032729\n",
       "5    context_utilization        0.019048              0.060646"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m = pd.DataFrame()\n",
    "df_m['metric'] = key\n",
    "df_m[\"Base BGE model\"] = v_m1\n",
    "df_m[\"Fine-tuned BGE model\"] = v_m2\n",
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7db5300a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>Base BGE model</th>\n",
       "      <th>Fine-tuned BGE model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.530952</td>\n",
       "      <td>0.578725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>context_precision</td>\n",
       "      <td>0.826190</td>\n",
       "      <td>0.765728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.564286</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context_entity_recall</td>\n",
       "      <td>0.038791</td>\n",
       "      <td>0.102261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>context_relevancy</td>\n",
       "      <td>0.062099</td>\n",
       "      <td>0.034310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>context_utilization</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.752446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  metric  Base BGE model  Fine-tuned BGE model\n",
       "0           faithfulness        0.530952              0.578725\n",
       "1      context_precision        0.826190              0.765728\n",
       "2         context_recall        0.564286              0.628571\n",
       "3  context_entity_recall        0.038791              0.102261\n",
       "4      context_relevancy        0.062099              0.034310\n",
       "5    context_utilization        0.821429              0.752446"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m = pd.DataFrame()\n",
    "df_m['metric'] = key\n",
    "df_m[\"Base BGE model\"] = v_m1\n",
    "df_m[\"Fine-tuned BGE model\"] = v_m2\n",
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72452826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned BGE model {'faithfulness': 0.5066, 'context_precision': 0.7636, 'context_recall': 0.6452}\n",
      "Base BGE model {'faithfulness': 0.5549, 'context_precision': 0.8024, 'context_recall': 0.5429}\n"
     ]
    }
   ],
   "source": [
    "print(\"Fine-tuned BGE model\",result2)\n",
    "print(\"Base BGE model\",result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8070d8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned BGE model {'faithfulness': 0.5793, 'context_precision': 0.7432, 'context_recall': 0.6210}\n",
      "Base BGE model {'faithfulness': 0.5704, 'context_precision': 0.7617, 'context_recall': 0.6714}\n"
     ]
    }
   ],
   "source": [
    "print(\"Fine-tuned BGE model\",result2)\n",
    "print(\"Base BGE model\",result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "37f48a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>* Which materials are in the dataset?</td>\n",
       "      <td>The materials in the dataset include MoS2, WSe...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>The materials in the dataset are MoS2 and WSe2.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* How many structures are there in the dataset?</td>\n",
       "      <td>The dataset contains a total of 14,866 structu...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>There are a total of 5933 defect configuration...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* How to obtain the dataset?</td>\n",
       "      <td>The datasets analyzed in the study can be obta...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>The dataset can be obtained by computing datas...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>* What is the dataset license?</td>\n",
       "      <td>The dataset is licensed under a Creative Commo...</td>\n",
       "      <td>[Supplementary information\\n\\nSupplementary Ma...</td>\n",
       "      <td>The dataset license is a Creative Commons Attr...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941518</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>* What is the data format?</td>\n",
       "      <td>The data format of the dataset is in CSV forma...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>The data format is structured datasets contain...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>* How to read the dataset?</td>\n",
       "      <td>To access and read the dataset, you can visit ...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>To read the dataset, one should start by under...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962654</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>* How to browse the dataset?</td>\n",
       "      <td>The dataset can be browsed and explored by dow...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>To browse the dataset mentioned in the context...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>* Can I work with the dataset without Python?</td>\n",
       "      <td>Yes, you can work with the dataset without Pyt...</td>\n",
       "      <td>[The same rationale can be used to structure t...</td>\n",
       "      <td>No, you cannot work with the dataset without P...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>* How to obtain the raw VASP files?</td>\n",
       "      <td>To obtain the raw VASP files, follow these ste...</td>\n",
       "      <td>[1a).\\n\\nThere are hundreds of existing 2D mat...</td>\n",
       "      <td>To obtain the raw VASP files, you can refer to...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.786111</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>* What were the settings used for the DFT comp...</td>\n",
       "      <td>The settings used for the DFT computations inc...</td>\n",
       "      <td>[The availability of such high-density defects...</td>\n",
       "      <td>The settings used for the DFT computations wer...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>* How well the DFT calculations correspond to ...</td>\n",
       "      <td>The provided context does not specifically add...</td>\n",
       "      <td>[The availability of such high-density defects...</td>\n",
       "      <td>The DFT calculations mentioned in the context ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>* How to cite the dataset?</td>\n",
       "      <td>To cite the dataset, you can use the provided ...</td>\n",
       "      <td>[a The space of defects in 2D materials and b ...</td>\n",
       "      <td>To cite the dataset, you can reference the ori...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>* What was the procedure for SRGNN quality eva...</td>\n",
       "      <td>The procedure for SRGNN quality evaluation inv...</td>\n",
       "      <td>[The performance values are presented in Table...</td>\n",
       "      <td>The procedure for SRGNN quality evaluation inv...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.725397</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>* How is SRGNN different from the baselines?</td>\n",
       "      <td>SRGNN differs from the baseline models by inco...</td>\n",
       "      <td>[We compare the performance of our sparse repr...</td>\n",
       "      <td>SRGNN (Sparse Representation Graph Neural Netw...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.884354</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>* What are the limitations of SRGNN?</td>\n",
       "      <td>The limitations of SRGNN are not explicitly me...</td>\n",
       "      <td>[In this spirit, a large number of computation...</td>\n",
       "      <td>The limitations of SRGNN (Sparse Representatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>* What is the core idea of SRGNN?</td>\n",
       "      <td>The core idea of SRGNN is to enhance the predi...</td>\n",
       "      <td>[As a future direction, in case generalization...</td>\n",
       "      <td>The core idea of SRGNN (Sparse Representation ...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>* How to run the code?</td>\n",
       "      <td>To run the code based on the provided context,...</td>\n",
       "      <td>[The performance values are presented in Table...</td>\n",
       "      <td>To run the code mentioned in the context, you ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>* Which frameworks were used for SRGNN impleme...</td>\n",
       "      <td>The SRGNN model was implemented using the PyTo...</td>\n",
       "      <td>[Since the materials we considered are normal ...</td>\n",
       "      <td>The frameworks used for SRGNN implementation w...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941518</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>* Can SRGNN be developed on a CPU, not a GPU?</td>\n",
       "      <td>Yes, SRGNN can be developed and trained on a C...</td>\n",
       "      <td>[Klicpera et al.14,17 (GemNet) redresses an im...</td>\n",
       "      <td>SRGNN (Sparse Representation Graph Neural Netw...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.653704</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>* What is the code license?</td>\n",
       "      <td>The code used for the SRGNN implementation is ...</td>\n",
       "      <td>[Supplementary information\\n\\nSupplementary Ma...</td>\n",
       "      <td>The code license is a Creative Commons Attribu...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>* How to cite the code?</td>\n",
       "      <td>To cite the code for the SRGNN model, you can ...</td>\n",
       "      <td>[The datasets as designed could provide traini...</td>\n",
       "      <td>To cite the code used in the study, you can re...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415476</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>* Which materials has the SRGNN been trained on?</td>\n",
       "      <td>The SRGNN has been trained on a dataset contai...</td>\n",
       "      <td>[Since the materials we considered are normal ...</td>\n",
       "      <td>The SRGNN has been trained on crystals blended...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.609259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>* Which materials can the SRGNN be trained on?</td>\n",
       "      <td>The SRGNN can be trained on a variety of atomi...</td>\n",
       "      <td>[Since the materials we considered are normal ...</td>\n",
       "      <td>The SRGNN (Sparse Representation Graph Neural ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915972</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>* Which defect types can the SRGNN be trained on?</td>\n",
       "      <td>SRGNN can be trained on various defect types p...</td>\n",
       "      <td>[Since the materials we considered are normal ...</td>\n",
       "      <td>The SRGNN (Sparse Representation Graph Neural ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895139</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>* How many structures are needed for SRGNN tra...</td>\n",
       "      <td>SRGNN typically requires a dataset containing ...</td>\n",
       "      <td>[Our studies demonstrate that the prediction e...</td>\n",
       "      <td>The number of structures needed for SRGNN trai...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668056</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>* Can SRGNN handle 3D materials?</td>\n",
       "      <td>SRGNN is specifically designed and optimized f...</td>\n",
       "      <td>[As a future direction, in case generalization...</td>\n",
       "      <td>Yes, SRGNN (Sparse Representation Graph Neural...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>* How much computational resources does SRGNN ...</td>\n",
       "      <td>Training a Sparse Representation Graph Neural ...</td>\n",
       "      <td>[Our studies demonstrate that the prediction e...</td>\n",
       "      <td>SRGNN (Sparse Representation Graph Neural Netw...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855258</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>* What is the inference speed of a SRGNN?</td>\n",
       "      <td>The inference speed of SRGNN, once trained, ca...</td>\n",
       "      <td>[Full size table\\n\\nIn terms of computation ti...</td>\n",
       "      <td>The inference speed of a SRGNN (Sparse Represe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>* Which properties can be predicted using SRGNN?</td>\n",
       "      <td>Formation energy per site and HOMO–LUMO gap. T...</td>\n",
       "      <td>[In this spirit, a large number of computation...</td>\n",
       "      <td>The properties that can be predicted using SRG...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952629</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>* What was the quality of SRGNN for each prope...</td>\n",
       "      <td>The quality of SRGNN for predicting properties...</td>\n",
       "      <td>[The performance values are presented in Table...</td>\n",
       "      <td>The quality of SRGNN for each property and mat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>* Can pre-trained SRGNN be used out-of-the-box?</td>\n",
       "      <td>Yes, a pre-trained SRGNN model can be used out...</td>\n",
       "      <td>[The model is trained with ordinary backpropag...</td>\n",
       "      <td>Yes, pre-trained SRGNN (Sparse Representation ...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.419444</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>* How well do SRGNN results correspond to expe...</td>\n",
       "      <td>The correspondence between SRGNN results and e...</td>\n",
       "      <td>[Our studies demonstrate that the prediction e...</td>\n",
       "      <td>The provided context does not contain specific...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883532</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>* Can I use SRGNN in place of DFT?</td>\n",
       "      <td>No, SRGNN can provide accurate predictions for...</td>\n",
       "      <td>[A similar descriptor-based approach is used i...</td>\n",
       "      <td>No, you cannot use SRGNN (Sparse Representatio...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785670</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>* How can I use SRGNN to find materials for so...</td>\n",
       "      <td>SRGNN can be used to predict properties of mat...</td>\n",
       "      <td>[In this spirit, a large number of computation...</td>\n",
       "      <td>You can use SRGNN (Structural Relation Graph N...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.644898</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>* Is SRGNN patented?</td>\n",
       "      <td>The patent status of SRGNN was not specified i...</td>\n",
       "      <td>[Klicpera et al.14,17 (GemNet) redresses an im...</td>\n",
       "      <td>I don't know if SRGNN (Sparse Representation G...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0               * Which materials are in the dataset?   \n",
       "1     * How many structures are there in the dataset?   \n",
       "2                        * How to obtain the dataset?   \n",
       "3                      * What is the dataset license?   \n",
       "4                          * What is the data format?   \n",
       "5                          * How to read the dataset?   \n",
       "6                        * How to browse the dataset?   \n",
       "7       * Can I work with the dataset without Python?   \n",
       "8                 * How to obtain the raw VASP files?   \n",
       "9   * What were the settings used for the DFT comp...   \n",
       "10  * How well the DFT calculations correspond to ...   \n",
       "11                         * How to cite the dataset?   \n",
       "12  * What was the procedure for SRGNN quality eva...   \n",
       "13       * How is SRGNN different from the baselines?   \n",
       "14               * What are the limitations of SRGNN?   \n",
       "15                  * What is the core idea of SRGNN?   \n",
       "16                             * How to run the code?   \n",
       "17  * Which frameworks were used for SRGNN impleme...   \n",
       "18      * Can SRGNN be developed on a CPU, not a GPU?   \n",
       "19                        * What is the code license?   \n",
       "20                            * How to cite the code?   \n",
       "21   * Which materials has the SRGNN been trained on?   \n",
       "22     * Which materials can the SRGNN be trained on?   \n",
       "23  * Which defect types can the SRGNN be trained on?   \n",
       "24  * How many structures are needed for SRGNN tra...   \n",
       "25                   * Can SRGNN handle 3D materials?   \n",
       "26  * How much computational resources does SRGNN ...   \n",
       "27          * What is the inference speed of a SRGNN?   \n",
       "28   * Which properties can be predicted using SRGNN?   \n",
       "29  * What was the quality of SRGNN for each prope...   \n",
       "30    * Can pre-trained SRGNN be used out-of-the-box?   \n",
       "31  * How well do SRGNN results correspond to expe...   \n",
       "32                 * Can I use SRGNN in place of DFT?   \n",
       "33  * How can I use SRGNN to find materials for so...   \n",
       "34                               * Is SRGNN patented?   \n",
       "\n",
       "                                         ground_truth  \\\n",
       "0   The materials in the dataset include MoS2, WSe...   \n",
       "1   The dataset contains a total of 14,866 structu...   \n",
       "2   The datasets analyzed in the study can be obta...   \n",
       "3   The dataset is licensed under a Creative Commo...   \n",
       "4   The data format of the dataset is in CSV forma...   \n",
       "5   To access and read the dataset, you can visit ...   \n",
       "6   The dataset can be browsed and explored by dow...   \n",
       "7   Yes, you can work with the dataset without Pyt...   \n",
       "8   To obtain the raw VASP files, follow these ste...   \n",
       "9   The settings used for the DFT computations inc...   \n",
       "10  The provided context does not specifically add...   \n",
       "11  To cite the dataset, you can use the provided ...   \n",
       "12  The procedure for SRGNN quality evaluation inv...   \n",
       "13  SRGNN differs from the baseline models by inco...   \n",
       "14  The limitations of SRGNN are not explicitly me...   \n",
       "15  The core idea of SRGNN is to enhance the predi...   \n",
       "16  To run the code based on the provided context,...   \n",
       "17  The SRGNN model was implemented using the PyTo...   \n",
       "18  Yes, SRGNN can be developed and trained on a C...   \n",
       "19  The code used for the SRGNN implementation is ...   \n",
       "20  To cite the code for the SRGNN model, you can ...   \n",
       "21  The SRGNN has been trained on a dataset contai...   \n",
       "22  The SRGNN can be trained on a variety of atomi...   \n",
       "23  SRGNN can be trained on various defect types p...   \n",
       "24  SRGNN typically requires a dataset containing ...   \n",
       "25  SRGNN is specifically designed and optimized f...   \n",
       "26  Training a Sparse Representation Graph Neural ...   \n",
       "27  The inference speed of SRGNN, once trained, ca...   \n",
       "28  Formation energy per site and HOMO–LUMO gap. T...   \n",
       "29  The quality of SRGNN for predicting properties...   \n",
       "30  Yes, a pre-trained SRGNN model can be used out...   \n",
       "31  The correspondence between SRGNN results and e...   \n",
       "32  No, SRGNN can provide accurate predictions for...   \n",
       "33  SRGNN can be used to predict properties of mat...   \n",
       "34  The patent status of SRGNN was not specified i...   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [a The space of defects in 2D materials and b ...   \n",
       "1   [a The space of defects in 2D materials and b ...   \n",
       "2   [a The space of defects in 2D materials and b ...   \n",
       "3   [Supplementary information\\n\\nSupplementary Ma...   \n",
       "4   [a The space of defects in 2D materials and b ...   \n",
       "5   [a The space of defects in 2D materials and b ...   \n",
       "6   [a The space of defects in 2D materials and b ...   \n",
       "7   [The same rationale can be used to structure t...   \n",
       "8   [1a).\\n\\nThere are hundreds of existing 2D mat...   \n",
       "9   [The availability of such high-density defects...   \n",
       "10  [The availability of such high-density defects...   \n",
       "11  [a The space of defects in 2D materials and b ...   \n",
       "12  [The performance values are presented in Table...   \n",
       "13  [We compare the performance of our sparse repr...   \n",
       "14  [In this spirit, a large number of computation...   \n",
       "15  [As a future direction, in case generalization...   \n",
       "16  [The performance values are presented in Table...   \n",
       "17  [Since the materials we considered are normal ...   \n",
       "18  [Klicpera et al.14,17 (GemNet) redresses an im...   \n",
       "19  [Supplementary information\\n\\nSupplementary Ma...   \n",
       "20  [The datasets as designed could provide traini...   \n",
       "21  [Since the materials we considered are normal ...   \n",
       "22  [Since the materials we considered are normal ...   \n",
       "23  [Since the materials we considered are normal ...   \n",
       "24  [Our studies demonstrate that the prediction e...   \n",
       "25  [As a future direction, in case generalization...   \n",
       "26  [Our studies demonstrate that the prediction e...   \n",
       "27  [Full size table\\n\\nIn terms of computation ti...   \n",
       "28  [In this spirit, a large number of computation...   \n",
       "29  [The performance values are presented in Table...   \n",
       "30  [The model is trained with ordinary backpropag...   \n",
       "31  [Our studies demonstrate that the prediction e...   \n",
       "32  [A similar descriptor-based approach is used i...   \n",
       "33  [In this spirit, a large number of computation...   \n",
       "34  [Klicpera et al.14,17 (GemNet) redresses an im...   \n",
       "\n",
       "                                               answer  faithfulness  \\\n",
       "0     The materials in the dataset are MoS2 and WSe2.      0.000000   \n",
       "1   There are a total of 5933 defect configuration...      0.666667   \n",
       "2   The dataset can be obtained by computing datas...      0.666667   \n",
       "3   The dataset license is a Creative Commons Attr...      1.000000   \n",
       "4   The data format is structured datasets contain...      1.000000   \n",
       "5   To read the dataset, one should start by under...      1.000000   \n",
       "6   To browse the dataset mentioned in the context...      1.000000   \n",
       "7   No, you cannot work with the dataset without P...      0.000000   \n",
       "8   To obtain the raw VASP files, you can refer to...      0.666667   \n",
       "9   The settings used for the DFT computations wer...      1.000000   \n",
       "10  The DFT calculations mentioned in the context ...           NaN   \n",
       "11  To cite the dataset, you can reference the ori...      0.857143   \n",
       "12  The procedure for SRGNN quality evaluation inv...      0.800000   \n",
       "13  SRGNN (Sparse Representation Graph Neural Netw...      0.800000   \n",
       "14  The limitations of SRGNN (Sparse Representatio...           NaN   \n",
       "15  The core idea of SRGNN (Sparse Representation ...      0.666667   \n",
       "16  To run the code mentioned in the context, you ...      0.000000   \n",
       "17  The frameworks used for SRGNN implementation w...      0.000000   \n",
       "18  SRGNN (Sparse Representation Graph Neural Netw...      0.750000   \n",
       "19  The code license is a Creative Commons Attribu...      0.000000   \n",
       "20  To cite the code used in the study, you can re...      0.000000   \n",
       "21  The SRGNN has been trained on crystals blended...      0.333333   \n",
       "22  The SRGNN (Sparse Representation Graph Neural ...      1.000000   \n",
       "23  The SRGNN (Sparse Representation Graph Neural ...      1.000000   \n",
       "24  The number of structures needed for SRGNN trai...      0.000000   \n",
       "25  Yes, SRGNN (Sparse Representation Graph Neural...      0.000000   \n",
       "26  SRGNN (Sparse Representation Graph Neural Netw...      1.000000   \n",
       "27  The inference speed of a SRGNN (Sparse Represe...      1.000000   \n",
       "28  The properties that can be predicted using SRG...      1.000000   \n",
       "29  The quality of SRGNN for each property and mat...           NaN   \n",
       "30  Yes, pre-trained SRGNN (Sparse Representation ...      0.500000   \n",
       "31  The provided context does not contain specific...      0.000000   \n",
       "32  No, you cannot use SRGNN (Sparse Representatio...      1.000000   \n",
       "33  You can use SRGNN (Structural Relation Graph N...      0.250000   \n",
       "34  I don't know if SRGNN (Sparse Representation G...           NaN   \n",
       "\n",
       "    context_precision  context_recall  \n",
       "0            1.000000        1.000000  \n",
       "1            0.988889        1.000000  \n",
       "2            0.988889        1.000000  \n",
       "3            0.941518        1.000000  \n",
       "4            1.000000        1.000000  \n",
       "5            0.962654        0.500000  \n",
       "6            1.000000        1.000000  \n",
       "7            1.000000        1.000000  \n",
       "8            0.786111        0.000000  \n",
       "9            0.988889        0.333333  \n",
       "10           0.000000        0.000000  \n",
       "11           0.583333        0.400000  \n",
       "12           0.725397        1.000000  \n",
       "13           0.884354        0.333333  \n",
       "14           0.000000        1.000000  \n",
       "15           0.325000        0.500000  \n",
       "16           1.000000        0.333333  \n",
       "17           0.941518        0.500000  \n",
       "18           0.653704        1.000000  \n",
       "19           0.916667        0.000000  \n",
       "20           0.415476        0.000000  \n",
       "21           0.609259        0.000000  \n",
       "22           0.915972        1.000000  \n",
       "23           0.895139        0.000000  \n",
       "24           0.668056        0.000000  \n",
       "25           1.000000        1.000000  \n",
       "26           0.855258        1.000000  \n",
       "27           0.278571        0.500000  \n",
       "28           0.952629        0.000000  \n",
       "29           1.000000        1.000000  \n",
       "30           0.419444        1.000000  \n",
       "31           0.883532        0.333333  \n",
       "32           0.785670        1.000000  \n",
       "33           0.644898        1.000000  \n",
       "34           0.000000        1.000000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "50f367d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.to_pandas().to_csv(\"./data/data_rag/ragas_metrics_ai4mat_bge_base.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9c51c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.to_pandas().to_csv(\"./data/data_rag/ragas_metrics_ai4mat_bge_fine_tuned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c31ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
