{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2588af5e",
   "metadata": {},
   "source": [
    "### Fine tune LLM embeedings model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2208c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai==0.28.1\n",
    "#!pip install openai --upgrade\n",
    "#!pip install ragas\n",
    "#!pip install unstructured\n",
    "#!pip install langchain[all]\n",
    "#!pip install --upgrade langchain\n",
    "\n",
    "#!pip install playwright\n",
    "#!pip install -U selenium unstructured\n",
    "#!pip install --upgrade langchain langchain-community langchainhub langchain-openai langchain-chroma bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d63c1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydantic==2.5\n",
    "#!pip install --upgrade --quiet  langchain_milvus\n",
    "#!pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3566c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e13d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "#import openai\n",
    "#from langchain.chat_models import ChatOpenAI, ChatGooglePalm\n",
    "from utils import OPENAI_API_KEY\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] =  OPENAI_API_KEY\n",
    "from llm_utils import *\n",
    "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "#openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2da0f4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59018bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (BertTokenizer, \n",
    "                          BertModel,\n",
    "                          BertForMaskedLM, \n",
    "                          Trainer, \n",
    "                          TrainingArguments, \n",
    "                          DataCollatorForLanguageModeling,\n",
    "                          DataCollatorForWholeWordMask,\n",
    "                          DataCollatorWithPadding\n",
    "                         )\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a449772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.chat_models import ChatOpenAI\n",
    "import langchain_core\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "from langchain_community.document_loaders import SeleniumURLLoader, TextLoader\n",
    "from langchain_text_splitters import (RecursiveCharacterTextSplitter, \n",
    "                                      TextSplitter,\n",
    "                                      NLTKTextSplitter,\n",
    "                                      SentenceTransformersTokenTextSplitter\n",
    "                                     )\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "ai_model = \"gpt-4o-mini\"\n",
    "\n",
    "llm = ChatOpenAI(model=ai_model, temperature=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfcbe35",
   "metadata": {},
   "source": [
    "### Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "456d2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_url_documets(list_urls, \n",
    "                      spliter=\"nltk\", \n",
    "                      tokens=512, \n",
    "                      overlap=0.1,\n",
    "                      embeedding_model=OpenAIEmbeddings(),\n",
    "                     ):\n",
    "    \n",
    "    overlap=int(overlap*tokens) if overlap>0 else 0\n",
    "    # Load, chunk and index the contents of the blog.\n",
    "    loader_url =SeleniumURLLoader( list_urls)\n",
    "    docs = loader_url.load()\n",
    "    if  spliter == \"nltk\":\n",
    "        text_splitter = NLTKTextSplitter(chunk_size=tokens, \n",
    "                                         chunk_overlap=overlap)\n",
    "        \n",
    "    elif spliter == \"sentence\":\n",
    "        text_splitter = SentenceTransformersTokenTextSplitter(chunk_size=tokens,\n",
    "                                                              model_name =\"BAAI/bge-base-en-v1.5\",\n",
    "                                                              chunk_overlap=overlap)\n",
    "        \n",
    "    elif spliter == \"recursive\":\n",
    "        text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\",\"\\n\"],\n",
    "                                                       chunk_size=tokens, \n",
    "                                                       chunk_overlap=overlap)\n",
    "        \n",
    "    elif spliter == \"semantic\":\n",
    "        text_splitter = SemanticChunker(embeedding_model,\n",
    "                                       breakpoint_threshold_amount=None,\n",
    "                                       number_of_chunks=None) \n",
    "                                                       \n",
    "                                                       \n",
    "    else:\n",
    "        print( f\"Unknown spliter {spliter}\")\n",
    "    \n",
    "    #text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\",\"\\n\"], chunk_size=500, chunk_overlap=50)\n",
    "    #text_splitter = NLTKTextSplitter(chunk_size=tokens, chunk_overlap=int(overlap*tokens))\n",
    "    #text_splitter = SentenceTransformersTokenTextSplitter()\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    \n",
    "    return splits, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90349841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1063, which is longer than the specified 50\n",
      "Created a chunk of size 137, which is longer than the specified 50\n",
      "Created a chunk of size 110, which is longer than the specified 50\n",
      "Created a chunk of size 146, which is longer than the specified 50\n",
      "Created a chunk of size 143, which is longer than the specified 50\n",
      "Created a chunk of size 128, which is longer than the specified 50\n",
      "Created a chunk of size 129, which is longer than the specified 50\n",
      "Created a chunk of size 539, which is longer than the specified 50\n",
      "Created a chunk of size 171, which is longer than the specified 50\n",
      "Created a chunk of size 210, which is longer than the specified 50\n",
      "Created a chunk of size 177, which is longer than the specified 50\n",
      "Created a chunk of size 253, which is longer than the specified 50\n",
      "Created a chunk of size 123, which is longer than the specified 50\n",
      "Created a chunk of size 87, which is longer than the specified 50\n",
      "Created a chunk of size 227, which is longer than the specified 50\n",
      "Created a chunk of size 130, which is longer than the specified 50\n",
      "Created a chunk of size 241, which is longer than the specified 50\n",
      "Created a chunk of size 134, which is longer than the specified 50\n",
      "Created a chunk of size 177, which is longer than the specified 50\n",
      "Created a chunk of size 213, which is longer than the specified 50\n",
      "Created a chunk of size 104, which is longer than the specified 50\n",
      "Created a chunk of size 106, which is longer than the specified 50\n",
      "Created a chunk of size 138, which is longer than the specified 50\n",
      "Created a chunk of size 133, which is longer than the specified 50\n",
      "Created a chunk of size 181, which is longer than the specified 50\n",
      "Created a chunk of size 190, which is longer than the specified 50\n",
      "Created a chunk of size 157, which is longer than the specified 50\n",
      "Created a chunk of size 209, which is longer than the specified 50\n",
      "Created a chunk of size 149, which is longer than the specified 50\n",
      "Created a chunk of size 138, which is longer than the specified 50\n",
      "Created a chunk of size 143, which is longer than the specified 50\n",
      "Created a chunk of size 222, which is longer than the specified 50\n",
      "Created a chunk of size 94, which is longer than the specified 50\n",
      "Created a chunk of size 92, which is longer than the specified 50\n",
      "Created a chunk of size 181, which is longer than the specified 50\n",
      "Created a chunk of size 73, which is longer than the specified 50\n",
      "Created a chunk of size 91, which is longer than the specified 50\n",
      "Created a chunk of size 188, which is longer than the specified 50\n",
      "Created a chunk of size 58, which is longer than the specified 50\n",
      "Created a chunk of size 192, which is longer than the specified 50\n",
      "Created a chunk of size 135, which is longer than the specified 50\n",
      "Created a chunk of size 201, which is longer than the specified 50\n",
      "Created a chunk of size 199, which is longer than the specified 50\n",
      "Created a chunk of size 257, which is longer than the specified 50\n",
      "Created a chunk of size 81, which is longer than the specified 50\n",
      "Created a chunk of size 141, which is longer than the specified 50\n",
      "Created a chunk of size 141, which is longer than the specified 50\n",
      "Created a chunk of size 149, which is longer than the specified 50\n",
      "Created a chunk of size 144, which is longer than the specified 50\n",
      "Created a chunk of size 209, which is longer than the specified 50\n",
      "Created a chunk of size 158, which is longer than the specified 50\n",
      "Created a chunk of size 118, which is longer than the specified 50\n",
      "Created a chunk of size 90, which is longer than the specified 50\n",
      "Created a chunk of size 84, which is longer than the specified 50\n",
      "Created a chunk of size 70, which is longer than the specified 50\n",
      "Created a chunk of size 104, which is longer than the specified 50\n",
      "Created a chunk of size 204, which is longer than the specified 50\n",
      "Created a chunk of size 243, which is longer than the specified 50\n",
      "Created a chunk of size 161, which is longer than the specified 50\n",
      "Created a chunk of size 172, which is longer than the specified 50\n",
      "Created a chunk of size 118, which is longer than the specified 50\n",
      "Created a chunk of size 51, which is longer than the specified 50\n",
      "Created a chunk of size 111, which is longer than the specified 50\n",
      "Created a chunk of size 105, which is longer than the specified 50\n",
      "Created a chunk of size 106, which is longer than the specified 50\n",
      "Created a chunk of size 99, which is longer than the specified 50\n",
      "Created a chunk of size 158, which is longer than the specified 50\n",
      "Created a chunk of size 80, which is longer than the specified 50\n",
      "Created a chunk of size 158, which is longer than the specified 50\n",
      "Created a chunk of size 166, which is longer than the specified 50\n",
      "Created a chunk of size 204, which is longer than the specified 50\n",
      "Created a chunk of size 79, which is longer than the specified 50\n",
      "Created a chunk of size 85, which is longer than the specified 50\n",
      "Created a chunk of size 68, which is longer than the specified 50\n",
      "Created a chunk of size 98, which is longer than the specified 50\n",
      "Created a chunk of size 165, which is longer than the specified 50\n",
      "Created a chunk of size 159, which is longer than the specified 50\n",
      "Created a chunk of size 110, which is longer than the specified 50\n",
      "Created a chunk of size 161, which is longer than the specified 50\n",
      "Created a chunk of size 310, which is longer than the specified 50\n",
      "Created a chunk of size 133, which is longer than the specified 50\n",
      "Created a chunk of size 214, which is longer than the specified 50\n",
      "Created a chunk of size 164, which is longer than the specified 50\n",
      "Created a chunk of size 53, which is longer than the specified 50\n",
      "Created a chunk of size 226, which is longer than the specified 50\n",
      "Created a chunk of size 185, which is longer than the specified 50\n",
      "Created a chunk of size 61, which is longer than the specified 50\n",
      "Created a chunk of size 128, which is longer than the specified 50\n",
      "Created a chunk of size 125, which is longer than the specified 50\n",
      "Created a chunk of size 186, which is longer than the specified 50\n",
      "Created a chunk of size 227, which is longer than the specified 50\n",
      "Created a chunk of size 126, which is longer than the specified 50\n",
      "Created a chunk of size 178, which is longer than the specified 50\n",
      "Created a chunk of size 97, which is longer than the specified 50\n",
      "Created a chunk of size 166, which is longer than the specified 50\n",
      "Created a chunk of size 94, which is longer than the specified 50\n",
      "Created a chunk of size 80, which is longer than the specified 50\n",
      "Created a chunk of size 274, which is longer than the specified 50\n",
      "Created a chunk of size 117, which is longer than the specified 50\n",
      "Created a chunk of size 247, which is longer than the specified 50\n",
      "Created a chunk of size 81, which is longer than the specified 50\n",
      "Created a chunk of size 59, which is longer than the specified 50\n",
      "Created a chunk of size 183, which is longer than the specified 50\n",
      "Created a chunk of size 181, which is longer than the specified 50\n",
      "Created a chunk of size 98, which is longer than the specified 50\n",
      "Created a chunk of size 131, which is longer than the specified 50\n",
      "Created a chunk of size 173, which is longer than the specified 50\n",
      "Created a chunk of size 53, which is longer than the specified 50\n",
      "Created a chunk of size 108, which is longer than the specified 50\n",
      "Created a chunk of size 161, which is longer than the specified 50\n",
      "Created a chunk of size 168, which is longer than the specified 50\n",
      "Created a chunk of size 76, which is longer than the specified 50\n",
      "Created a chunk of size 120, which is longer than the specified 50\n",
      "Created a chunk of size 162, which is longer than the specified 50\n",
      "Created a chunk of size 71, which is longer than the specified 50\n",
      "Created a chunk of size 219, which is longer than the specified 50\n",
      "Created a chunk of size 277, which is longer than the specified 50\n",
      "Created a chunk of size 87, which is longer than the specified 50\n",
      "Created a chunk of size 64, which is longer than the specified 50\n",
      "Created a chunk of size 113, which is longer than the specified 50\n",
      "Created a chunk of size 88, which is longer than the specified 50\n",
      "Created a chunk of size 137, which is longer than the specified 50\n",
      "Created a chunk of size 528, which is longer than the specified 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 310, which is longer than the specified 50\n",
      "Created a chunk of size 146, which is longer than the specified 50\n",
      "Created a chunk of size 112, which is longer than the specified 50\n",
      "Created a chunk of size 117, which is longer than the specified 50\n",
      "Created a chunk of size 147, which is longer than the specified 50\n",
      "Created a chunk of size 105, which is longer than the specified 50\n",
      "Created a chunk of size 104, which is longer than the specified 50\n",
      "Created a chunk of size 74, which is longer than the specified 50\n",
      "Created a chunk of size 265, which is longer than the specified 50\n",
      "Created a chunk of size 87, which is longer than the specified 50\n",
      "Created a chunk of size 174, which is longer than the specified 50\n",
      "Created a chunk of size 73, which is longer than the specified 50\n",
      "Created a chunk of size 96, which is longer than the specified 50\n",
      "Created a chunk of size 458, which is longer than the specified 50\n",
      "Created a chunk of size 200, which is longer than the specified 50\n",
      "Created a chunk of size 488, which is longer than the specified 50\n",
      "Created a chunk of size 215, which is longer than the specified 50\n",
      "Created a chunk of size 150, which is longer than the specified 50\n",
      "Created a chunk of size 105, which is longer than the specified 50\n",
      "Created a chunk of size 166, which is longer than the specified 50\n",
      "Created a chunk of size 93, which is longer than the specified 50\n",
      "Created a chunk of size 238, which is longer than the specified 50\n",
      "Created a chunk of size 218, which is longer than the specified 50\n",
      "Created a chunk of size 144, which is longer than the specified 50\n",
      "Created a chunk of size 62, which is longer than the specified 50\n",
      "Created a chunk of size 159, which is longer than the specified 50\n",
      "Created a chunk of size 124, which is longer than the specified 50\n",
      "Created a chunk of size 115, which is longer than the specified 50\n",
      "Created a chunk of size 95, which is longer than the specified 50\n",
      "Created a chunk of size 68, which is longer than the specified 50\n",
      "Created a chunk of size 161, which is longer than the specified 50\n",
      "Created a chunk of size 106, which is longer than the specified 50\n",
      "Created a chunk of size 111, which is longer than the specified 50\n",
      "Created a chunk of size 115, which is longer than the specified 50\n",
      "Created a chunk of size 154, which is longer than the specified 50\n",
      "Created a chunk of size 144, which is longer than the specified 50\n",
      "Created a chunk of size 95, which is longer than the specified 50\n",
      "Created a chunk of size 283, which is longer than the specified 50\n",
      "Created a chunk of size 219, which is longer than the specified 50\n",
      "Created a chunk of size 109, which is longer than the specified 50\n",
      "Created a chunk of size 166, which is longer than the specified 50\n",
      "Created a chunk of size 99, which is longer than the specified 50\n",
      "Created a chunk of size 90, which is longer than the specified 50\n",
      "Created a chunk of size 143, which is longer than the specified 50\n",
      "Created a chunk of size 62, which is longer than the specified 50\n",
      "Created a chunk of size 94, which is longer than the specified 50\n",
      "Created a chunk of size 121, which is longer than the specified 50\n",
      "Created a chunk of size 110, which is longer than the specified 50\n",
      "Created a chunk of size 167, which is longer than the specified 50\n",
      "Created a chunk of size 100, which is longer than the specified 50\n",
      "Created a chunk of size 101, which is longer than the specified 50\n",
      "Created a chunk of size 176, which is longer than the specified 50\n",
      "Created a chunk of size 140, which is longer than the specified 50\n",
      "Created a chunk of size 84, which is longer than the specified 50\n",
      "Created a chunk of size 92, which is longer than the specified 50\n",
      "Created a chunk of size 268, which is longer than the specified 50\n",
      "Created a chunk of size 187, which is longer than the specified 50\n",
      "Created a chunk of size 165, which is longer than the specified 50\n",
      "Created a chunk of size 194, which is longer than the specified 50\n",
      "Created a chunk of size 228, which is longer than the specified 50\n",
      "Created a chunk of size 89, which is longer than the specified 50\n",
      "Created a chunk of size 141, which is longer than the specified 50\n",
      "Created a chunk of size 270, which is longer than the specified 50\n",
      "Created a chunk of size 176, which is longer than the specified 50\n",
      "Created a chunk of size 157, which is longer than the specified 50\n",
      "Created a chunk of size 129, which is longer than the specified 50\n",
      "Created a chunk of size 113, which is longer than the specified 50\n",
      "Created a chunk of size 94, which is longer than the specified 50\n",
      "Created a chunk of size 63, which is longer than the specified 50\n",
      "Created a chunk of size 187, which is longer than the specified 50\n",
      "Created a chunk of size 162, which is longer than the specified 50\n",
      "Created a chunk of size 60, which is longer than the specified 50\n",
      "Created a chunk of size 109, which is longer than the specified 50\n",
      "Created a chunk of size 164, which is longer than the specified 50\n",
      "Created a chunk of size 148, which is longer than the specified 50\n",
      "Created a chunk of size 123, which is longer than the specified 50\n",
      "Created a chunk of size 218, which is longer than the specified 50\n",
      "Created a chunk of size 195, which is longer than the specified 50\n",
      "Created a chunk of size 93, which is longer than the specified 50\n",
      "Created a chunk of size 198, which is longer than the specified 50\n",
      "Created a chunk of size 577, which is longer than the specified 50\n",
      "Created a chunk of size 949, which is longer than the specified 50\n",
      "Created a chunk of size 198, which is longer than the specified 50\n",
      "Created a chunk of size 208, which is longer than the specified 50\n",
      "Created a chunk of size 115, which is longer than the specified 50\n",
      "Created a chunk of size 151, which is longer than the specified 50\n",
      "Created a chunk of size 242, which is longer than the specified 50\n",
      "Created a chunk of size 64, which is longer than the specified 50\n",
      "Created a chunk of size 113, which is longer than the specified 50\n",
      "Created a chunk of size 100, which is longer than the specified 50\n",
      "Created a chunk of size 59, which is longer than the specified 50\n",
      "Created a chunk of size 161, which is longer than the specified 50\n",
      "Created a chunk of size 138, which is longer than the specified 50\n",
      "Created a chunk of size 117, which is longer than the specified 50\n",
      "Created a chunk of size 111, which is longer than the specified 50\n",
      "Created a chunk of size 59, which is longer than the specified 50\n",
      "Created a chunk of size 95, which is longer than the specified 50\n",
      "Created a chunk of size 98, which is longer than the specified 50\n",
      "Created a chunk of size 183, which is longer than the specified 50\n",
      "Created a chunk of size 92, which is longer than the specified 50\n",
      "Created a chunk of size 58, which is longer than the specified 50\n",
      "Created a chunk of size 89, which is longer than the specified 50\n",
      "Created a chunk of size 116, which is longer than the specified 50\n",
      "Created a chunk of size 251, which is longer than the specified 50\n",
      "Created a chunk of size 150, which is longer than the specified 50\n",
      "Created a chunk of size 218, which is longer than the specified 50\n",
      "Created a chunk of size 142, which is longer than the specified 50\n",
      "Created a chunk of size 80, which is longer than the specified 50\n",
      "Created a chunk of size 177, which is longer than the specified 50\n",
      "Created a chunk of size 114, which is longer than the specified 50\n",
      "Created a chunk of size 202, which is longer than the specified 50\n",
      "Created a chunk of size 98, which is longer than the specified 50\n",
      "Created a chunk of size 65, which is longer than the specified 50\n",
      "Created a chunk of size 82, which is longer than the specified 50\n",
      "Created a chunk of size 52, which is longer than the specified 50\n",
      "Created a chunk of size 65, which is longer than the specified 50\n",
      "Created a chunk of size 52, which is longer than the specified 50\n",
      "Created a chunk of size 107, which is longer than the specified 50\n",
      "Created a chunk of size 79, which is longer than the specified 50\n",
      "Created a chunk of size 62, which is longer than the specified 50\n",
      "Created a chunk of size 67, which is longer than the specified 50\n",
      "Created a chunk of size 52, which is longer than the specified 50\n",
      "Created a chunk of size 96, which is longer than the specified 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 54, which is longer than the specified 50\n",
      "Created a chunk of size 139, which is longer than the specified 50\n",
      "Created a chunk of size 109, which is longer than the specified 50\n",
      "Created a chunk of size 194, which is longer than the specified 50\n",
      "Created a chunk of size 52, which is longer than the specified 50\n",
      "Created a chunk of size 64, which is longer than the specified 50\n",
      "Created a chunk of size 130, which is longer than the specified 50\n",
      "Created a chunk of size 161, which is longer than the specified 50\n",
      "Created a chunk of size 90, which is longer than the specified 50\n",
      "Created a chunk of size 59, which is longer than the specified 50\n",
      "Created a chunk of size 95, which is longer than the specified 50\n",
      "Created a chunk of size 84, which is longer than the specified 50\n",
      "Created a chunk of size 102, which is longer than the specified 50\n",
      "Created a chunk of size 71, which is longer than the specified 50\n",
      "Created a chunk of size 65, which is longer than the specified 50\n",
      "Created a chunk of size 96, which is longer than the specified 50\n",
      "Created a chunk of size 116, which is longer than the specified 50\n",
      "Created a chunk of size 105, which is longer than the specified 50\n",
      "Created a chunk of size 84, which is longer than the specified 50\n",
      "Created a chunk of size 121, which is longer than the specified 50\n",
      "Created a chunk of size 68, which is longer than the specified 50\n",
      "Created a chunk of size 86, which is longer than the specified 50\n",
      "Created a chunk of size 98, which is longer than the specified 50\n",
      "Created a chunk of size 203, which is longer than the specified 50\n",
      "Created a chunk of size 104, which is longer than the specified 50\n",
      "Created a chunk of size 108, which is longer than the specified 50\n",
      "Created a chunk of size 97, which is longer than the specified 50\n",
      "Created a chunk of size 106, which is longer than the specified 50\n",
      "Created a chunk of size 109, which is longer than the specified 50\n",
      "Created a chunk of size 121, which is longer than the specified 50\n",
      "Created a chunk of size 92, which is longer than the specified 50\n",
      "Created a chunk of size 63, which is longer than the specified 50\n",
      "Created a chunk of size 58, which is longer than the specified 50\n",
      "Created a chunk of size 65, which is longer than the specified 50\n",
      "Created a chunk of size 126, which is longer than the specified 50\n",
      "Created a chunk of size 95, which is longer than the specified 50\n",
      "Created a chunk of size 98, which is longer than the specified 50\n",
      "Created a chunk of size 97, which is longer than the specified 50\n",
      "Created a chunk of size 58, which is longer than the specified 50\n",
      "Created a chunk of size 94, which is longer than the specified 50\n",
      "Created a chunk of size 128, which is longer than the specified 50\n",
      "Created a chunk of size 310, which is longer than the specified 50\n",
      "Created a chunk of size 78, which is longer than the specified 50\n",
      "Created a chunk of size 106, which is longer than the specified 50\n",
      "Created a chunk of size 102, which is longer than the specified 50\n",
      "Created a chunk of size 129, which is longer than the specified 50\n",
      "Created a chunk of size 164, which is longer than the specified 50\n",
      "Created a chunk of size 137, which is longer than the specified 50\n",
      "Created a chunk of size 69, which is longer than the specified 50\n",
      "Created a chunk of size 111, which is longer than the specified 50\n",
      "Created a chunk of size 722, which is longer than the specified 50\n",
      "Created a chunk of size 1304, which is longer than the specified 50\n",
      "Created a chunk of size 172, which is longer than the specified 50\n",
      "Created a chunk of size 162, which is longer than the specified 50\n",
      "Created a chunk of size 79, which is longer than the specified 50\n",
      "Created a chunk of size 147, which is longer than the specified 50\n",
      "Created a chunk of size 121, which is longer than the specified 50\n",
      "Created a chunk of size 113, which is longer than the specified 50\n",
      "Created a chunk of size 85, which is longer than the specified 50\n",
      "Created a chunk of size 159, which is longer than the specified 50\n",
      "Created a chunk of size 435, which is longer than the specified 50\n",
      "Created a chunk of size 173, which is longer than the specified 50\n",
      "Created a chunk of size 233, which is longer than the specified 50\n",
      "Created a chunk of size 82, which is longer than the specified 50\n",
      "Created a chunk of size 112, which is longer than the specified 50\n",
      "Created a chunk of size 85, which is longer than the specified 50\n",
      "Created a chunk of size 349, which is longer than the specified 50\n",
      "Created a chunk of size 463, which is longer than the specified 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 1\n"
     ]
    }
   ],
   "source": [
    "url_list = [\n",
    "           \"https://www.nature.com/articles/s41524-023-01062-z\",\n",
    "        #    \"https://www.nature.com/articles/s41699-023-00369-1\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/tree/main/docs/CONSTRUCTOR-MOCK.md\"\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/CONSTRUCTOR.md\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/DATA.md\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/ENVIRONMENT.md\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/GENERATING-CONSTRUCTOR.md\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/GENERATING-MOCK.md\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/PILOT.md\",\n",
    "        #    \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/SPARSE-PAPER.md\"\n",
    "        #    \"https://www.nature.com/articles/s41377-024-01407-3\",\n",
    "        #    \"https://www.nature.com/articles/s41565-023-01407-1\",\n",
    "        #    \"https://www.nature.com/articles/s41699-023-00369-1\",\n",
    "           ]\n",
    "                               \n",
    "chunks, documents = load_url_documets(url_list, spliter =\"nltk\", tokens=50)\n",
    "print(len(chunks), len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ea47c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Machine Learning\n",
      "2. Materials Science\n",
      "3. Defect Analysis in Crystals\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "\n",
    "ai_model = \"gpt-4o-mini\"\n",
    "\n",
    "llm = ChatOpenAI(model=ai_model, temperature=0.)\n",
    "\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "qa_document_chain = AnalyzeDocumentChain(combine_docs_chain=qa_chain, \n",
    "                                         text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, \n",
    "                                                                                      chunk_overlap=100))\n",
    "\n",
    "answer = qa_document_chain.run(\n",
    "    input_document=documents[0].page_content,\n",
    "    question=(\"\"\"\n",
    "     You are an expert in analyzing scientific papers.\n",
    "     Read the text carefully and answer the question:\n",
    "     What are the main three scientific subject areas of research and text study?\n",
    "     Give the answer as a list.\n",
    "    \"\"\"\n",
    "            )\n",
    "             )\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb3567e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the most exciting characteristics of 2D crystals is the ability to tune their properties via controllable introduction of defects. However, the search space for such structures is enormous, and ab-initio computations prohibitively expensive. We propose a machine learning approach for rapid estimation of the properties of 2D material given the lattice structure and defect configuration. The method suggests a way to represent configuration of 2D materials with defects that allows a neural network to train quickly and accurately.\n",
      "\n",
      "We compare our methodology with the state-of-the-art approaches and demonstrate at least 3.7 times energy prediction error drop.\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([ch.page_content for ch in chunks[1:5]]))\n",
    "print()\n",
    "print(chunks[5].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb8d119",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bd941c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_core\n",
    "def prepare_example_conversation(sentence1, sentence2, expert):\n",
    "    \"\"\"\n",
    "    Create the data of QA the model.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    \n",
    "    if type(sentence1) == list:\n",
    "        content1 = \" \".join([s.page_content for s in sentence1])\n",
    "    elif type(sentence1) == str:\n",
    "        content1 = sentence1\n",
    "    elif type(sentence1) == langchain_core.documents.base.Document:\n",
    "        content1 = sentence1.page_content\n",
    "    else:\n",
    "        print(\"Unknown type of seentence1\")\n",
    "        \n",
    "    if type(sentence2) == list:\n",
    "        content2 = \" \".join([s.page_content for s in sentence2])\n",
    "    elif type(sentence2) == str:\n",
    "        content2 = sentence2\n",
    "    elif type(sentence2) == langchain_core.documents.base.Document:\n",
    "        content2 = sentence2.page_content\n",
    "    else:\n",
    "        print(\"Unknown type of seentence2\")\n",
    "        \n",
    "    system_message = f\"You are an expert  in {expert}. Your task is to continue given user's text.\"\n",
    "    \n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": content1})\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"content\": content2})\n",
    "\n",
    "    return {\"messages\": messages} \n",
    "\n",
    "    \n",
    "#{\"prompt\": \"The quick brown fox jumps over the lazy dog.\\n\\n\", \"completion\": \"The fox then ran towards the forest, ready for the next adventure.\"}\n",
    "#{\"prompt\": \"It was a sunny day and the birds were chirping.\\n\\n\", \"completion\": \"The park was filled with families enjoying the weather and children playing.\"}\n",
    "\n",
    "\n",
    "\n",
    "#print(prepare_example_conversation(chunks[0:5], chunks[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d96c707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning, Materials Science, Quantum Phyics,'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert = \"  \".join([w.strip() for w in [\"Machine Learning, Materials Science, Quantum Phyics,\"]\n",
    "                     ])\n",
    "expert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98169cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393\n"
     ]
    }
   ],
   "source": [
    "train_size = 1\n",
    "win_size = 5\n",
    "tr_int = int(len(chunks) * train_size)\n",
    "\n",
    "training_dataset = []\n",
    "\n",
    "                \n",
    "for i  in range(1, len(chunks) - win_size):\n",
    "    \n",
    "    training_dataset.append(prepare_example_conversation(chunks[i:i+win_size], chunks[i+win_size], expert))\n",
    "    \n",
    "print(len(training_dataset))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e19c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_prompts(data):\n",
    "    #c_data = []\n",
    "    for d in data:\n",
    "        c_data = []\n",
    "        for  m in d[\"messages\"]:\n",
    "            #m[\"content\"] = m[\"content\"].replace(\"\\n\\n\", \"\\n\")\n",
    "            c_data.append( {\"role\": m[\"role\"], \"content\": m[\"content\"].replace( \"\\n\", \" \")})\n",
    "        d[\"messages\"] =  c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86d33709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_prompts(data):\n",
    "    c_data = []\n",
    "    for d in data:\n",
    "        _data = []\n",
    "        for  m in d[\"messages\"]:\n",
    "            if len(m[\"content\"].split(\"\\n\")) == 1:\n",
    "                _data.append( {\"role\": m[\"role\"], \"content\": m[\"content\"]})\n",
    "        if len(_data) == 3:\n",
    "            c_data.append({\"messages\":  _data})\n",
    "    return c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31bc9d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "cl_data = clear_prompts(training_dataset)\n",
    "print(len(cl_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f7472f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 21\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "\n",
    "training_data = cl_data[:int(len(cl_data) * train_size)]\n",
    "validation_data = cl_data[int(len(cl_data) * train_size):]\n",
    "print(len(training_data), len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccdaaa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': \"You are an expert  in Machine Learning, Materials Science, Quantum Phyics,. Your task is to continue given user's text.\"},\n",
       "  {'role': 'user',\n",
       "   'content': 'Controllable defect engineering, i.e., introduction of vacancies or desired impurities, enables properties modifications and new functionalities in crystalline materials1. The opportunities for such controlled material engineering methods got a dramatic boost in the past two decades with the development of the methods for exfoliation of crystal into two-dimensional atomic layer2. The reduced dimensionality in layered two-dimensional materials makes it possible to manipulate defects atom by atom and tune their properties down to quantum mechanics limits3. Such atomic-scale preparation and fabrication techniques hold promise for the continual development of the semiconductor industry in the post-Moore age and the development of novel technologies such as quantum computing4, catalysts5, and photovoltaics6. Despite decades of research efforts, knowledge of the structure-property relation for defects in crystals is still limited.'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Only a small subset of defects in the vast configuration space have been investigated7.'}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e92b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_jsonl(data_list: list, filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Write a training file\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as out:\n",
    "        for ddict in data_list:\n",
    "            jout = json.dumps(ddict) + \"\\n\"\n",
    "            out.write(jout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7519890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = \"tmp_ai4material_training_cl.jsonl\"\n",
    "write_jsonl(training_data, training_file_name)\n",
    "\n",
    "validation_file_name = \"tmp_ai4material__validation_cl.jsonl\"\n",
    "write_jsonl(validation_data, validation_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b9041",
   "metadata": {},
   "source": [
    "### Upload files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "69f526c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-NYumpxMVH0tOAc5DunIk2qbp\n",
      "Validation file ID: file-szEUv3gDWdfwLrToddu5XIwH\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY )\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d23c2f",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1729db54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-klyexzicQmFqofpDUS4350Ur\n",
      "Status: validating_files\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # gpt-3.5-turbo-1106\n",
    "    suffix=\"ai4materials\",\n",
    "    hyperparameters = {\"batch_size\": 4,\n",
    "                       \"learning_rate_multiplier\": 1e-4,\n",
    "                       \"n_epochs\": 3}\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "46238db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-klyexzicQmFqofpDUS4350Ur\n",
      "Status: validating_files\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7f535c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fine-tuning job: ftjob-klyexzicQmFqofpDUS4350Ur\n",
      "Validating training file: file-NYumpxMVH0tOAc5DunIk2qbp and validation file: file-szEUv3gDWdfwLrToddu5XIwH\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=50)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b2d57",
   "metadata": {},
   "source": [
    "### Masking Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f4a8917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9a71039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controllable defect engineering, i.e., introduction of vacancies or desired impurities, enables properties modifications and new functionalities in crystalline materials1. The opportunities for such controlled material engineering methods got a dramatic boost in the past two decades with the development of the methods for exfoliation of crystal into two-dimensional atomic layer2. The reduced dimensionality in layered two-dimensional materials makes it possible to manipulate defects atom by atom and tune their properties down to quantum mechanics limits3. Such atomic-scale preparation and fabrication techniques hold promise for the continual development of the semiconductor industry in the post-Moore age and the development of novel technologies such as quantum computing4, catalysts5, and photovoltaics6. Despite decades of research efforts, knowledge of the structure-property relation for defects in crystals is still limited.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Controllable defect engineering, i.e., introduction of vacancies or desired impurities, enables properties modifications and new functionalities in crystalline materials1. The opportunities for such controlled material  ...  methods got a dramatic  ...  in the past two decades with the development of the methods for exfoliation of crystal into two-dimensional atomic layer2. The reduced  ...  in layered two-dimensional materials makes it possible to  ...  defects atom by atom and tune their properties down to quantum mechanics limits3. Such atomic-scale  ...  and  ...  techniques hold promise for the continual development of the  ...  industry in the post-Moore age and the development of novel technologies such as quantum computing4, catalysts5, and photovoltaics6. Despite decades of research  ...  knowledge of the structure-property relation for defects in crystals is still limited.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def  mask_text(text, p=0.3, ns=4):\n",
    "    sl = text.split(' ')\n",
    "    sl_len = list(map(len, sl))\n",
    "    #mask = list(map(lambda x: random.random() <1-p if x else True > ns,  sl_len))\n",
    "    #return \" \".join([s if m else \" ... \" for s,m in zip(sl, mask) ])\n",
    "    \n",
    "    mask = np.random.choice([True, False], size=len(sl), p=[1 -p, p])\n",
    "    return \" \".join([s if (m or n < ns) else \" ... \" for s,m,n in zip(sl, mask, sl_len) ])\n",
    "\n",
    "s = training_data[1][\"messages\"][1][\"content\"]\n",
    "print(s)\n",
    "mask_text(s, 0.1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77120af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_data(data, expert, p=0.2):\n",
    "    \n",
    "    system_message = f\"\"\"You are an expert in {expert}. \n",
    "    Your task is to fill in the gaps marked ... in this text with the most appropriate words \n",
    "    based on the context and area of expertise. \"\"\"\n",
    "    \n",
    "    masked_data = []\n",
    "        \n",
    "    for d in data:\n",
    "        masked_messages = []\n",
    "        \n",
    "        i = 0\n",
    "        m = d[\"messages\"][i]\n",
    "        while m['role'] != 'user':\n",
    "            m = d[\"messages\"][i]\n",
    "            content = m[\"content\"]\n",
    "            i += 1\n",
    "            \n",
    "        masked_messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "        masked_messages.append({\"role\": \"user\", \"content\": mask_text(content, p)})\n",
    "        masked_messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "        \n",
    "        masked_data.append({\"messages\": masked_messages})\n",
    "    return masked_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "980fcd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_training_data = masking_data(training_data, expert, 0.1)\n",
    "masked_validation_data = masking_data(validation_data, expert, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "dd32366d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'You are an expert in Machine Learning, Materials Science, Quantum Phyics,. \\n    Your task is to fill in the gaps marked ... in this text with the most appropriate words \\n    based on the context and area of expertise. '},\n",
       "  {'role': 'user',\n",
       "   'content': 'One of the  ...  exciting characteristics of 2D crystals is the ability to tune their properties via controllable introduction of defects. However, the  ...  space for such structures is enormous, and ab-initio  ...  prohibitively expensive. We propose a machine learning approach for rapid estimation of the properties of 2D material given the lattice structure and defect configuration. The method suggests a way to represent configuration of 2D materials with defects that allows a neural network to train quickly and accurately. We compare our methodology with the  ...  approaches and demonstrate at least 3.7 times energy prediction error drop.'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'One of the most exciting characteristics of 2D crystals is the ability to tune their properties via controllable introduction of defects. However, the search space for such structures is enormous, and ab-initio computations prohibitively expensive. We propose a machine learning approach for rapid estimation of the properties of 2D material given the lattice structure and defect configuration. The method suggests a way to represent configuration of 2D materials with defects that allows a neural network to train quickly and accurately. We compare our methodology with the state-of-the-art approaches and demonstrate at least 3.7 times energy prediction error drop.'}]}"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "3536d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = \"tmp_ai4material_training_cl.jsonl\"\n",
    "write_jsonl(masked_training_data, training_file_name)\n",
    "\n",
    "validation_file_name = \"tmp_ai4material__validation_cl.jsonl\"\n",
    "write_jsonl(masked_validation_data, validation_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77ce6eb",
   "metadata": {},
   "source": [
    "### Upload files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "24e3fe76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-j61cZitIP6VwyJzEhVwQw9ks\n",
      "Validation file ID: file-gaxBl02EVDNNXMLcIRVs53cC\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY )\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a14ee",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "c2eb3be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-AOO3sWe83ikrlZVo4wc4OLVX\n",
      "Status: validating_files\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # gpt-3.5-turbo-1106\n",
    "    suffix=\"ai4materials_v0\",\n",
    "    hyperparameters = {\"batch_size\": 4,\n",
    "                       \"learning_rate_multiplier\": 1e-4,\n",
    "                       \"n_epochs\": 3}\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5bf59f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-AOO3sWe83ikrlZVo4wc4OLVX\n",
      "Status: validating_files\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "2b7852bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fine-tuning job: ftjob-AOO3sWe83ikrlZVo4wc4OLVX\n",
      "Validating training file: file-j61cZitIP6VwyJzEhVwQw9ks and validation file: file-gaxBl02EVDNNXMLcIRVs53cC\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=50)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3cc80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fineTuningOpenai(data_tr, \n",
    "                     data_val,\n",
    "                     expert, \n",
    "                     file_name,\n",
    "                     p=0.1,\n",
    "                     model=\"gpt-4o-mini-2024-07-18\",  # gpt-3.5-turbo-1106\n",
    "                     suffix=\"ai4materials_v0\",\n",
    "                     batch_size=4,\n",
    "                     learing_rate_multiplier=1e-4,\n",
    "                     n_epochs=3\n",
    "                    ):\n",
    "                     \n",
    "    import openai\n",
    "    \n",
    "    masked_training_data = masking_data(data_tr, expert, p)\n",
    "    masked_validation_data = masking_data(data_val, expert, p)\n",
    "    print(\"Masked training data\", len(masked_training_data), \"validation data\", len(masked_validation_data))\n",
    "    data = { \"training\": masked_training_data, \n",
    "            \"validation\": masked_validation_data}\n",
    "    \n",
    "    training_file_name = f\"data/data_rag/{file_name}_training.jsonl\"\n",
    "    write_jsonl(masked_training_data, training_file_name)\n",
    "\n",
    "    validation_file_name = f\"data/data_rag/{file_name}_validation.jsonl\"\n",
    "    write_jsonl(masked_validation_data, validation_file_name)\n",
    "    \n",
    "    client = openai.OpenAI(api_key=OPENAI_API_KEY )\n",
    "\n",
    "    training_response = client.files.create(\n",
    "        file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    "    )\n",
    "    training_file_id = training_response.id\n",
    "\n",
    "\n",
    "    validation_response = client.files.create(\n",
    "        file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    "    )\n",
    "    validation_file_id = validation_response.id\n",
    "\n",
    "    print(\"Training file ID:\", training_file_id)\n",
    "    print(\"Validation file ID:\", validation_file_id)\n",
    "    \n",
    "    response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=model,  # gpt-4o-mini-2024-07-18\n",
    "    suffix=suffix, #ai4materials_v0\n",
    "    hyperparameters = {\"batch_size\": batch_size,\n",
    "                       \"learning_rate_multiplier\": learing_rate_multiplier,\n",
    "                       \"n_epochs\": n_epochs}\n",
    "    )\n",
    "\n",
    "    job_id = response.id\n",
    "\n",
    "    print(\"Job ID:\", response.id)\n",
    "    print(\"Status:\", response.status)\n",
    "    \n",
    "    response = client.fine_tuning.jobs.retrieve(response.id)\n",
    "\n",
    "    print(\"Job ID:\", response.id)\n",
    "    print(\"Status:\", response.status)\n",
    "    print(\"Trained Tokens:\", response.trained_tokens)\n",
    "\n",
    "    return response, job_id, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10f67b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked training data 83 validation data 21\n",
      "Training file ID: file-q7y2Vx82TCeXLE76uFf1wKqt\n",
      "Validation file ID: file-e8nYglfyXWj2vmftK793KFxt\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Model text-embedding-ada-002 is not available for fine-tuning or does not exist.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m p \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m----> 2\u001b[0m response, job_id, data \u001b[38;5;241m=\u001b[39m \u001b[43mfineTuningOpenai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mexpert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                 \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtmp_ai4material_v\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mp\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m#model=\"gpt-4o-mini-2024-07-18\",  # gpt-3.5-turbo-1106\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-embedding-ada-002\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mai4materials_v\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mp\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mlearing_rate_multiplier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 43\u001b[0m, in \u001b[0;36mfineTuningOpenai\u001b[0;34m(data_tr, data_val, expert, file_name, p, model, suffix, batch_size, learing_rate_multiplier, n_epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining file ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, training_file_id)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation file ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, validation_file_id)\n\u001b[0;32m---> 43\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tuning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_file_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_file_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# gpt-4o-mini-2024-07-18\u001b[39;49;00m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#ai4materials_v0\u001b[39;49;00m\n\u001b[1;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate_multiplier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearing_rate_multiplier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m job_id \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mid\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mid)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.10/site-packages/openai/resources/fine_tuning/jobs/jobs.py:133\u001b[0m, in \u001b[0;36mJobs.create\u001b[0;34m(self, model, training_file, hyperparameters, integrations, seed, suffix, validation_file, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m     68\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FineTuningJob:\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    Creates a fine-tuning job which begins the process of creating a new model from\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    a given dataset.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/fine_tuning/jobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhyperparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintegrations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegrations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuffix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjob_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJobCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFineTuningJob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1265\u001b[0m     )\n\u001b[0;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.10/site-packages/openai/_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1045\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1049\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1050\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1054\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Model text-embedding-ada-002 is not available for fine-tuning or does not exist.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}"
     ]
    }
   ],
   "source": [
    "p =0.2\n",
    "response, job_id, data = fineTuningOpenai(training_data,\n",
    "                 validation_data,\n",
    "                 expert,\n",
    "                 f\"tmp_ai4material_v{p}\",\n",
    "                 p=p,\n",
    "                 #model=\"gpt-4o-mini-2024-07-18\",  # gpt-3.5-turbo-1106\n",
    "                 model = \"text-embedding-ada-002\",\n",
    "                 suffix=f\"ai4materials_v{p}\",\n",
    "                 batch_size=8,\n",
    "                 learing_rate_multiplier=1e-6,\n",
    "                 n_epochs=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79bd2fed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fine-tuning job: ftjob-fX6xeJf2NPGF8ypU7YafOKgR\n",
      "Validating training file: file-ivEcZtskI3Me4DchryNXsJ4C and validation file: file-YOIaUvi37c5eFr4a7wj5UyiM\n",
      "Files validated, moving job to queued state\n",
      "Fine-tuning job started\n",
      "Step 1/32: training loss=0.48, validation loss=0.40\n",
      "Step 2/32: training loss=0.60, validation loss=0.23\n",
      "Step 3/32: training loss=0.56, validation loss=0.46\n",
      "Step 4/32: training loss=0.52, validation loss=0.26\n",
      "Step 5/32: training loss=0.63, validation loss=0.27\n",
      "Step 6/32: training loss=0.62, validation loss=0.38\n",
      "Step 7/32: training loss=0.44, validation loss=0.32\n",
      "Step 8/32: training loss=0.48, validation loss=0.30\n",
      "Step 9/32: training loss=0.62, validation loss=0.34\n",
      "Step 10/32: training loss=0.57, validation loss=0.22, full validation loss=0.27\n",
      "Step 11/32: training loss=0.34, validation loss=0.42\n",
      "Step 12/32: training loss=0.60, validation loss=0.37\n",
      "Step 13/32: training loss=0.63, validation loss=0.21\n",
      "Step 14/32: training loss=0.41, validation loss=0.42\n",
      "Step 15/32: training loss=0.48, validation loss=0.29\n",
      "Step 16/32: training loss=0.82, validation loss=0.35\n",
      "Step 17/32: training loss=0.65, validation loss=0.28\n",
      "Step 18/32: training loss=0.71, validation loss=0.26\n",
      "Step 19/32: training loss=0.34, validation loss=0.36\n",
      "Step 20/32: training loss=0.42, validation loss=0.33, full validation loss=0.27\n",
      "Step 21/32: training loss=0.45, validation loss=0.22\n",
      "Step 22/32: training loss=0.49, validation loss=0.40\n",
      "Step 23/32: training loss=0.60, validation loss=0.23\n",
      "Step 24/32: training loss=0.55, validation loss=0.46\n",
      "Step 25/32: training loss=0.53, validation loss=0.26\n",
      "Step 26/32: training loss=0.41, validation loss=0.27\n",
      "Step 27/32: training loss=0.42, validation loss=0.38\n",
      "Step 28/32: training loss=0.58, validation loss=0.32\n",
      "Step 29/32: training loss=0.60, validation loss=0.30\n",
      "Step 30/32: training loss=0.79, validation loss=0.34, full validation loss=0.27\n",
      "Step 31/32: training loss=0.40, validation loss=0.22\n",
      "Step 32/32: training loss=0.52, validation loss=0.42\n",
      "Checkpoint created at step 20\n",
      "Checkpoint created at step 30\n",
      "New fine-tuned model created\n",
      "Evaluating model against our usage policies before enabling\n",
      "Usage policy evaluations completed, model is now enabled for sampling\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY )\n",
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=50)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "8c7671d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fine_tuning.job.event'"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event.object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f49b1c",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a68a4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(messages, model):\n",
    "    \n",
    "    try:\n",
    "        from openai import ChatCompletion\n",
    "        \n",
    "        response = ChatCompletion.create(\n",
    "                   model=model,\n",
    "                   messages=messages,\n",
    "                   temperature=0, \n",
    "                    )\n",
    "        \n",
    "        return response#.choices[0].message[\"content\"]\n",
    "    \n",
    "    except:\n",
    "        from openai import OpenAI\n",
    "        \n",
    "        client = OpenAI(api_key=OPENAI_API_KEY )\n",
    "        response = client.chat.completions.create(\n",
    "                          model=model,\n",
    "                   messages=messages,\n",
    "                   temperature=0 \n",
    "                   )\n",
    "        return response.choices[0].message.content  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa6184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80515823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'You are an expert in Machine Learning, Materials Science, Quantum Phyics,. \\n    Your task is to fill in the gaps marked ... in this text with the most appropriate words \\n    based on the context and area of expertise. '},\n",
       "  {'role': 'user',\n",
       "   'content': 'We use a value averaged over 12 experiments, same as in  ...  2 to estimate training stability. For formation  ...   ...   ...  the z coordinate difference in sparse representation edges  ...  the Sparse-Z model to  ...  the Full model everywhere except h-BN; adding pristine atom species  ...  as the node features contributes the most of the remaining gain. The most likely explanation for the importance of the pristine  ...  for h-BN is  ...  both atoms can be substituted to C, without this additional information, the model can’t distinguish between B and N substitutions. Adding EOS improves expected prediction quality and stability by a small amount for the low-density datasets. For HOMO–LUMO  ...  Sparse-Z-Were and Sparse-Z-Were-EOS perform similarly to Full in terms of the combined metric,  ...  it by a factor of 4 for low-density data.'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'We use a value averaged over 12 experiments, same as in Table 2 to estimate training stability. For formation energy, just enabling the z coordinate difference in sparse representation edges allows the Sparse-Z model to outperform the Full model everywhere except h-BN; adding pristine atom species (Sparse-Z-Were) as the node features contributes the most of the remaining gain. The most likely explanation for the importance of the pristine species for h-BN is that both atoms can be substituted to C, without this additional information, the model can’t distinguish between B and N substitutions. Adding EOS improves expected prediction quality and stability by a small amount for the low-density datasets. For HOMO–LUMO gap, Sparse-Z-Were and Sparse-Z-Were-EOS perform similarly to Full in terms of the combined metric, outperform it by a factor of 4 for low-density data.'}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "b395657f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use a value averaged over 12 experiments, same as in Table 2 to estimate training stability. For formation  ...  just enabling the z coordinate difference in sparse representation edges allows the Sparse-Z model to outperform the Full model  ...  except h-BN; adding pristine  ...  species (Sparse-Z-Were) as the node  ...  contributes the most of the remaining gain. The most likely explanation for the importance of the pristine species for  ...  is that both atoms can be substituted to C, without this additional information, the model can’t distinguish between B and N substitutions. Adding EOS  ...  expected prediction quality and stability by a small amount for the low-density datasets. For  ...  gap, Sparse-Z-Were and Sparse-Z-Were-EOS perform similarly to  ...  in terms of the combined metric, outperform it by a factor of 4 for low-density data.\n",
      "\n",
      "We use a value averaged over 12 experiments, same as in Table 2 to estimate training stability. For formation energy, just enabling the z coordinate difference in sparse representation edges allows the Sparse-Z model to outperform the Full model everywhere except h-BN; adding pristine atom species (Sparse-Z-Were) as the node features contributes the most of the remaining gain. The most likely explanation for the importance of the pristine species for h-BN is that both atoms can be substituted to C, without this additional information, the model can’t distinguish between B and N substitutions. Adding EOS improves expected prediction quality and stability by a small amount for the low-density datasets. For HOMO–LUMO gap, Sparse-Z-Were and Sparse-Z-Were-EOS perform similarly to Full in terms of the combined metric, outperform it by a factor of 4 for low-density data.\n"
     ]
    }
   ],
   "source": [
    "print(data[\"validation\"][0]['messages'][1]['content'])\n",
    "print()\n",
    "print(data[\"validation\"][0]['messages'][2]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "24d0d2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use a value averaged over 12 experiments, same as in Table 2 to estimate training stability. For formation  ...  just enabling the z coordinate difference in sparse representation edges allows the Sparse-Z model to outperform the Full model  ...  except h-BN; adding pristine  ...  species (Sparse-Z-Were) as the node  ...  contributes the most of the remaining gain. The most likely explanation for the importance of the pristine species for  ...  is that both atoms can be substituted to C, without this additional information, the model can’t distinguish between B and N substitutions. Adding EOS  ...  expected prediction quality and stability by a small amount for the low-density datasets. For  ...  gap, Sparse-Z-Were and Sparse-Z-Were-EOS perform similarly to  ...  in terms of the combined metric, outperform it by a factor of 4 for low-density data.\n",
      "\n",
      "We use a value averaged over 12 experiments, same as in Table 2 to estimate training stability. For formation energy, just enabling the z coordinate difference in sparse representation edges allows the Sparse-Z model to outperform the Full model everywhere except h-BN; adding pristine atom species (Sparse-Z-Were) as the node features contributes the most of the remaining gain. The most likely explanation for the importance of the pristine species for h-BN is that both atoms can be substituted to C, without this additional information, the model can’t distinguish between B and N substitutions. Adding EOS improves expected prediction quality and stability by a small amount for the low-density datasets. For HOMO–LUMO gap, Sparse-Z-Were and Sparse-Z-Were-EOS perform similarly to Full in terms of the combined metric, outperform it by a factor of 4 for low-density data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We use a value averaged over 12 experiments, same as in Table 2 to estimate training stability. For formation **energy**, just enabling the z coordinate difference in sparse representation edges allows the Sparse-Z model to outperform the Full model **in all cases** except h-BN; adding pristine **carbon** species (Sparse-Z-Were) as the node **feature** contributes the most of the remaining gain. The most likely explanation for the importance of the pristine species for **model performance** is that both atoms can be substituted to C, without this additional information, the model can’t distinguish between B and N substitutions. Adding EOS **(Equation of State)** expected prediction quality and stability by a small amount for the low-density datasets. For **the band** gap, Sparse-Z-Were and Sparse-Z-Were-EOS perform similarly to **the baseline model** in terms of the combined metric, outperform it by a factor of 4 for low-density data.'"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j=0\n",
    "test_messages = []\n",
    "test_messages.append({\"role\": \"system\", \n",
    "                      \"content\": data[\"validation\"][j]['messages'][0]['content']})\n",
    "\n",
    "test_messages.append({\"role\": \"user\", \n",
    "                      \"content\": data[\"validation\"][j]['messages'][1]['content']})\n",
    "print(test_messages[1]['content'])\n",
    "print()\n",
    "print(data[\"validation\"][j]['messages'][2]['content'])\n",
    "\n",
    "get_completion(test_messages, \n",
    "               \"ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v01:9xuixRUZ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081e46b6",
   "metadata": {},
   "source": [
    "### Next step MASKING p =0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5dc9f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked training data 83 validation data 21\n",
      "Training file ID: file-6C51nKKQyegyG0pJakAjAeyD\n",
      "Validation file ID: file-ixGnmLjjc16GB7HBR5rVy9UV\n",
      "Job ID: ftjob-Gf93iwgLnje3rlsI7Z5rmL9Z\n",
      "Status: validating_files\n",
      "Job ID: ftjob-Gf93iwgLnje3rlsI7Z5rmL9Z\n",
      "Status: validating_files\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "p =0.2\n",
    "response, job_id, data = fineTuningOpenai(training_data,\n",
    "                 validation_data,\n",
    "                 expert,\n",
    "                 f\"tmp_ai4material_v{p}\",\n",
    "                 p=p,\n",
    "                 model=\"ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v01:9xuixRUZ\",  # gpt-3.5-turbo-1106\n",
    "                 suffix=f\"ai4materials_v{p}\",\n",
    "                 batch_size=4,\n",
    "                 learing_rate_multiplier=1e-6,\n",
    "                 n_epochs=2,\n",
    "                                         )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62364eb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fine-tuning job: ftjob-Gf93iwgLnje3rlsI7Z5rmL9Z\n",
      "Validating training file: file-6C51nKKQyegyG0pJakAjAeyD and validation file: file-ixGnmLjjc16GB7HBR5rVy9UV\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY )\n",
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=50)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "165e7bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their  ...  nature makes them prone to  ...  modification,  ...  further increases their  ...  for a variety of applications. However, the search space for possible configurations is  ...  Thus, the ability to predict the  ...  of such crystals efficiently  ...  a vital task. In this  ...  we focus on predicting the properties of  ...  crystals blended with defects, substitutions, and  ...  State-of-the-art  ...  learning algorithms struggle to learn the properties of crystals’ defects accurately.\n",
      "\n",
      "Their two-dimensional nature makes them prone to chemical modification, which further increases their tunability for a variety of applications. However, the search space for possible configurations is vast. Thus, the ability to predict the properties of such crystals efficiently becomes a vital task. In this paper, we focus on predicting the properties of such crystals blended with defects, substitutions, and vacancies. State-of-the-art machine learning algorithms struggle to learn the properties of crystals’ defects accurately.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Their **intrinsic** nature makes them prone to **structural** modification, **which** further increases their **versatility** for a variety of applications. However, the search space for possible configurations is **vast**. Thus, the ability to predict the **properties** of such crystals efficiently **remains** a vital task. In this **study**, we focus on predicting the properties of **metallic** crystals blended with defects, substitutions, and **impurities**. State-of-the-art **machine** learning algorithms struggle to learn the properties of crystals’ defects accurately.'"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j=1\n",
    "test_messages = []\n",
    "test_messages.append({\"role\": \"system\", \n",
    "                      \"content\": data[\"validation\"][j]['messages'][0]['content']})\n",
    "\n",
    "test_messages.append({\"role\": \"user\", \n",
    "                      \"content\": data[\"validation\"][j]['messages'][1]['content']})\n",
    "print(test_messages[1]['content'])\n",
    "print()\n",
    "print(data[\"validation\"][j]['messages'][2]['content'])\n",
    "\n",
    "get_completion(test_messages, \n",
    "               \"ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-2:9xuy5Jqv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee16447a",
   "metadata": {},
   "source": [
    "### Next step MASKING p =0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "e21398f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked training data 83 validation data 21\n",
      "Training file ID: file-EWhiHueGlalALXTBoP36NG1Z\n",
      "Validation file ID: file-zXyseBW7zspmAy2sMgUAIZ5y\n",
      "Job ID: ftjob-vR2VsXAwHzuLgRICRvG25gy3\n",
      "Status: validating_files\n",
      "Job ID: ftjob-vR2VsXAwHzuLgRICRvG25gy3\n",
      "Status: validating_files\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "p =0.3\n",
    "response, job_id, data = fineTuningOpenai(training_data,\n",
    "                 validation_data,\n",
    "                 expert,\n",
    "                 f\"tmp_ai4material_v{p}\",\n",
    "                 p=p,\n",
    "                 model=\"ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-2:9xuy5Jqv\",  # gpt-3.5-turbo-1106\n",
    "                 suffix=f\"ai4materials_v{p}\",)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "6f883e94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18/63: training loss=0.94, validation loss=0.39\n",
      "Step 19/63: training loss=0.69, validation loss=0.66\n",
      "Step 20/63: training loss=0.78, validation loss=0.26, full validation loss=0.46\n",
      "Step 21/63: training loss=1.06, validation loss=0.91\n",
      "Step 22/63: training loss=0.99, validation loss=0.75\n",
      "Step 23/63: training loss=0.58, validation loss=0.59\n",
      "Step 24/63: training loss=0.63, validation loss=0.64\n",
      "Step 25/63: training loss=0.85, validation loss=0.20\n",
      "Step 26/63: training loss=0.75, validation loss=0.72\n",
      "Step 27/63: training loss=1.00, validation loss=1.02\n",
      "Step 28/63: training loss=0.92, validation loss=0.42\n",
      "Step 29/63: training loss=0.79, validation loss=0.63\n",
      "Step 30/63: training loss=0.90, validation loss=0.34\n",
      "Step 31/63: training loss=0.85, validation loss=0.62\n",
      "Step 32/63: training loss=0.63, validation loss=0.95\n",
      "Step 33/63: training loss=0.79, validation loss=0.59\n",
      "Step 34/63: training loss=0.96, validation loss=0.57\n",
      "Step 35/63: training loss=0.53, validation loss=0.44\n",
      "Step 36/63: training loss=0.79, validation loss=0.39\n",
      "Step 37/63: training loss=1.02, validation loss=0.95\n",
      "Step 38/63: training loss=1.14, validation loss=0.55\n",
      "Step 39/63: training loss=0.71, validation loss=0.39\n",
      "Step 40/63: training loss=0.54, validation loss=0.66, full validation loss=0.46\n",
      "Step 41/63: training loss=0.66, validation loss=0.26\n",
      "Step 42/63: training loss=0.65, validation loss=0.91\n",
      "Step 43/63: training loss=0.66, validation loss=0.75\n",
      "Step 44/63: training loss=0.53, validation loss=0.59\n",
      "Step 45/63: training loss=0.90, validation loss=0.64\n",
      "Step 46/63: training loss=0.93, validation loss=0.21\n",
      "Step 47/63: training loss=0.72, validation loss=0.72\n",
      "Step 48/63: training loss=0.66, validation loss=1.03\n",
      "Step 49/63: training loss=0.70, validation loss=0.42\n",
      "Step 50/63: training loss=0.71, validation loss=0.64\n",
      "Step 51/63: training loss=0.84, validation loss=0.34\n",
      "Step 52/63: training loss=0.91, validation loss=0.62\n",
      "Step 53/63: training loss=0.85, validation loss=0.95\n",
      "Step 54/63: training loss=0.81, validation loss=0.59\n",
      "Step 55/63: training loss=0.80, validation loss=0.57\n",
      "Step 56/63: training loss=1.04, validation loss=0.44\n",
      "Step 57/63: training loss=0.89, validation loss=0.39\n",
      "Step 58/63: training loss=0.96, validation loss=0.95\n",
      "Step 59/63: training loss=0.74, validation loss=0.56\n",
      "Step 60/63: training loss=0.94, validation loss=0.39, full validation loss=0.46\n",
      "Step 61/63: training loss=0.69, validation loss=0.66\n",
      "Step 62/63: training loss=0.91, validation loss=0.26\n",
      "Step 63/63: training loss=0.45, validation loss=0.91\n",
      "Checkpoint created at step 40 with Snapshot ID: ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-3:9xv8G4L7:ckpt-step-40\n",
      "Checkpoint created at step 60 with Snapshot ID: ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-3:9xv8GST7:ckpt-step-60\n",
      "New fine-tuned model created: ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-3:9xv8GRrq\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=50)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "b4286b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = events[-2].message.split(\" \")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f2b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAIEmbedding.create(model=\"text-embedding-ada-002\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "d7ab155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their two-dimensional nature  ...  them prone to  ...  modification, which further increases their tunability for a variety of  ...  However, the search space for possible  ...  is vast. Thus, the  ...  to predict the properties of  ...   ...   ...  becomes a vital  ...  In this paper, we focus on predicting the properties of such crystals blended  ...  defects, substitutions, and vacancies.  ...   ...   ...  algorithms  ...  to  ...  the properties of  ...  defects accurately.\n",
      "\n",
      "Their two-dimensional nature makes them prone to chemical modification, which further increases their tunability for a variety of applications. However, the search space for possible configurations is vast. Thus, the ability to predict the properties of such crystals efficiently becomes a vital task. In this paper, we focus on predicting the properties of such crystals blended with defects, substitutions, and vacancies. State-of-the-art machine learning algorithms struggle to learn the properties of crystals’ defects accurately.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Their two-dimensional nature **makes** them prone to **structural** modification, which further increases their tunability for a variety of **applications**. However, the search space for possible **configurations** is vast. Thus, the **ability** to predict the properties of **two-dimensional materials** becomes a vital **task**. In this paper, we focus on predicting the properties of such crystals blended **with** defects, substitutions, and vacancies. **Machine learning** algorithms **are employed** to **model** the properties of **these** defects accurately.'"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j=1\n",
    "test_messages = []\n",
    "test_messages.append({\"role\": \"system\", \n",
    "                      \"content\": data[\"validation\"][j]['messages'][0]['content']})\n",
    "\n",
    "test_messages.append({\"role\": \"user\", \n",
    "                      \"content\": data[\"validation\"][j]['messages'][1]['content']})\n",
    "print(test_messages[1]['content'])\n",
    "print()\n",
    "print(data[\"validation\"][j]['messages'][2]['content'])\n",
    "\n",
    "get_completion(test_messages, ft_model)\n",
    "             #  \"ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-3:9xv8GRrq\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ba212",
   "metadata": {},
   "source": [
    "### Next step MASKING p =0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "e85ef4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked training data 83 validation data 21\n",
      "Training file ID: file-pE1F6bEcHTFiCjOJeejpSFpu\n",
      "Validation file ID: file-oTspWNLJ9KYJuupu56BsGal6\n",
      "Job ID: ftjob-v1HwcNteEegHKoU0pylbtEOD\n",
      "Status: validating_files\n",
      "Job ID: ftjob-v1HwcNteEegHKoU0pylbtEOD\n",
      "Status: validating_files\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "p =0.4\n",
    "print(\"Fine-Tune:\",ft_model)\n",
    "response, job_id, data = fineTuningOpenai(training_data,\n",
    "                 validation_data,\n",
    "                 expert,\n",
    "                 f\"tmp_ai4material_v{p}\",\n",
    "                 p=p,\n",
    "                 model=ft_model,  # gpt-3.5-turbo-1106\n",
    "                 suffix=f\"ai4materials_v{p}\",)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "2b22166c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18/63: training loss=1.05, validation loss=0.67\n",
      "Step 19/63: training loss=1.39, validation loss=0.97\n",
      "Step 20/63: training loss=1.42, validation loss=0.50, full validation loss=0.66\n",
      "Step 21/63: training loss=1.14, validation loss=1.12\n",
      "Step 22/63: training loss=1.27, validation loss=1.08\n",
      "Step 23/63: training loss=0.95, validation loss=0.68\n",
      "Step 24/63: training loss=0.99, validation loss=1.10\n",
      "Step 25/63: training loss=1.13, validation loss=0.40\n",
      "Step 26/63: training loss=1.18, validation loss=0.86\n",
      "Step 27/63: training loss=1.03, validation loss=1.55\n",
      "Step 28/63: training loss=0.86, validation loss=0.70\n",
      "Step 29/63: training loss=1.33, validation loss=1.00\n",
      "Step 30/63: training loss=1.10, validation loss=0.48\n",
      "Step 31/63: training loss=1.15, validation loss=0.72\n",
      "Step 32/63: training loss=1.13, validation loss=1.48\n",
      "Step 33/63: training loss=1.16, validation loss=0.82\n",
      "Step 34/63: training loss=0.88, validation loss=0.62\n",
      "Step 35/63: training loss=0.98, validation loss=0.57\n",
      "Step 36/63: training loss=1.12, validation loss=0.68\n",
      "Step 37/63: training loss=0.98, validation loss=1.37\n",
      "Step 38/63: training loss=1.11, validation loss=0.75\n",
      "Step 39/63: training loss=0.94, validation loss=0.68\n",
      "Step 40/63: training loss=1.19, validation loss=0.95, full validation loss=0.66\n",
      "Step 41/63: training loss=1.23, validation loss=0.50\n",
      "Step 42/63: training loss=1.10, validation loss=1.12\n",
      "Step 43/63: training loss=1.25, validation loss=1.08\n",
      "Step 44/63: training loss=1.22, validation loss=0.67\n",
      "Step 45/63: training loss=1.25, validation loss=1.10\n",
      "Step 46/63: training loss=1.14, validation loss=0.40\n",
      "Step 47/63: training loss=1.12, validation loss=0.86\n",
      "Step 48/63: training loss=1.21, validation loss=1.55\n",
      "Step 49/63: training loss=1.43, validation loss=0.70\n",
      "Step 50/63: training loss=1.28, validation loss=1.00\n",
      "Step 51/63: training loss=0.97, validation loss=0.48\n",
      "Step 52/63: training loss=1.05, validation loss=0.72\n",
      "Step 53/63: training loss=0.95, validation loss=1.47\n",
      "Step 54/63: training loss=0.96, validation loss=0.82\n",
      "Step 55/63: training loss=1.00, validation loss=0.64\n",
      "Step 56/63: training loss=0.73, validation loss=0.58\n",
      "Step 57/63: training loss=1.43, validation loss=0.67\n",
      "Step 58/63: training loss=1.26, validation loss=1.38\n",
      "Step 59/63: training loss=1.22, validation loss=0.75\n",
      "Step 60/63: training loss=1.26, validation loss=0.68, full validation loss=0.66\n",
      "Step 61/63: training loss=1.01, validation loss=0.94\n",
      "Step 62/63: training loss=1.02, validation loss=0.50\n",
      "Step 63/63: training loss=1.16, validation loss=1.12\n",
      "Checkpoint created at step 40 with Snapshot ID: ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-4:9xvNMyHT:ckpt-step-40\n",
      "Checkpoint created at step 60 with Snapshot ID: ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-4:9xvNMo2o:ckpt-step-60\n",
      "New fine-tuned model created: ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-4:9xvNMZT0\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=50)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "c5b7bd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-4:9xvNMZT0'"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model = events[-2].message.split(\" \")[-1]\n",
    "ft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "5ac880f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their two-dimensional nature  ...   ...   ...  to  ...   ...   ...  further increases their tunability for a variety of applications.  ...  the search  ...  for  ...  configurations is vast. Thus, the ability to  ...  the properties of such  ...   ...  becomes a  ...  task. In this paper, we focus on  ...  the  ...  of such  ...  blended  ...  defects, substitutions, and  ...  State-of-the-art machine  ...  algorithms struggle to learn the properties of crystals’ defects accurately.\n",
      "\n",
      "Their two-dimensional nature makes them prone to chemical modification, which further increases their tunability for a variety of applications. However, the search space for possible configurations is vast. Thus, the ability to predict the properties of such crystals efficiently becomes a vital task. In this paper, we focus on predicting the properties of such crystals blended with defects, substitutions, and vacancies. State-of-the-art machine learning algorithms struggle to learn the properties of crystals’ defects accurately.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Their two-dimensional nature **contributes significantly** to **enhanced performance**, which further increases their tunability for a variety of applications. **Consequently**, the search **space** for **optimal** configurations is vast. Thus, the ability to **manipulate** the properties of such **materials** becomes a **challenging** task. In this paper, we focus on **investigating** the **effects** of such **materials**, blended **with** defects, substitutions, and **interstitials**. State-of-the-art machine **learning** algorithms struggle to learn the properties of crystals’ defects accurately.'"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j=1\n",
    "test_messages = []\n",
    "test_messages.append({\"role\": \"system\", \n",
    "                      \"content\": data[\"validation\"][j]['messages'][0]['content']})\n",
    "\n",
    "test_messages.append({\"role\": \"user\", \n",
    "                      \"content\": data[\"validation\"][j]['messages'][1]['content']})\n",
    "print(test_messages[1]['content'])\n",
    "print()\n",
    "print(data[\"validation\"][j]['messages'][2]['content'])\n",
    "\n",
    "get_completion(test_messages, ft_model)\n",
    "             #  \"ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-3:9xv8GRrq\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf011e",
   "metadata": {},
   "source": [
    "### Next step MASKING p =0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "778cf017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tune: ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-4:9xvNMZT0\n",
      "Masked training data 83 validation data 21\n",
      "Training file ID: file-PMLMu5V5v7ZXri3pyA54nya8\n",
      "Validation file ID: file-CwLw8gY009ioAOLnYdqtfmDI\n",
      "Job ID: ftjob-5eO1UihoRUsKZNzQ1yqKggOB\n",
      "Status: validating_files\n",
      "Job ID: ftjob-5eO1UihoRUsKZNzQ1yqKggOB\n",
      "Status: validating_files\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "p =0.5\n",
    "print(\"Fine-Tune:\",ft_model)\n",
    "response, job_id, data = fineTuningOpenai(training_data,\n",
    "                 validation_data,\n",
    "                 expert,\n",
    "                 f\"tmp_ai4material_v{p}\",\n",
    "                 p=p,\n",
    "                 model=ft_model,  # gpt-3.5-turbo-1106\n",
    "                 suffix=f\"ai4materials_v{p}\",)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "49ba658d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18/63: training loss=1.32, validation loss=0.88\n",
      "Step 19/63: training loss=1.42, validation loss=1.17\n",
      "Step 20/63: training loss=1.46, validation loss=0.37, full validation loss=0.68\n",
      "Step 21/63: training loss=1.19, validation loss=1.01\n",
      "Step 22/63: training loss=1.40, validation loss=1.03\n",
      "Step 23/63: training loss=1.34, validation loss=0.97\n",
      "Step 24/63: training loss=1.21, validation loss=1.11\n",
      "Step 25/63: training loss=1.40, validation loss=0.48\n",
      "Step 26/63: training loss=1.44, validation loss=0.96\n",
      "Step 27/63: training loss=1.35, validation loss=1.16\n",
      "Step 28/63: training loss=1.24, validation loss=1.00\n",
      "Step 29/63: training loss=1.16, validation loss=0.85\n",
      "Step 30/63: training loss=1.63, validation loss=0.71\n",
      "Step 31/63: training loss=1.53, validation loss=0.69\n",
      "Step 32/63: training loss=1.54, validation loss=1.19\n",
      "Step 33/63: training loss=1.57, validation loss=0.74\n",
      "Step 34/63: training loss=1.38, validation loss=0.88\n",
      "Step 35/63: training loss=1.56, validation loss=0.88\n",
      "Step 36/63: training loss=1.57, validation loss=0.65\n",
      "Step 37/63: training loss=1.34, validation loss=1.00\n",
      "Step 38/63: training loss=1.31, validation loss=0.77\n",
      "Step 39/63: training loss=1.64, validation loss=0.88\n",
      "Step 40/63: training loss=1.35, validation loss=1.18, full validation loss=0.68\n",
      "Step 41/63: training loss=1.28, validation loss=0.38\n",
      "Step 42/63: training loss=1.50, validation loss=0.99\n",
      "Step 43/63: training loss=1.58, validation loss=1.02\n",
      "Step 44/63: training loss=1.62, validation loss=0.98\n",
      "Step 45/63: training loss=1.61, validation loss=1.14\n",
      "Step 46/63: training loss=1.64, validation loss=0.49\n",
      "Step 47/63: training loss=1.44, validation loss=0.96\n",
      "Step 48/63: training loss=1.18, validation loss=1.17\n",
      "Step 49/63: training loss=1.38, validation loss=1.00\n",
      "Step 50/63: training loss=1.18, validation loss=0.85\n",
      "Step 51/63: training loss=1.55, validation loss=0.70\n",
      "Step 52/63: training loss=0.96, validation loss=0.68\n",
      "Step 53/63: training loss=1.23, validation loss=1.18\n",
      "Step 54/63: training loss=1.11, validation loss=0.73\n",
      "Step 55/63: training loss=1.23, validation loss=0.88\n",
      "Step 56/63: training loss=1.25, validation loss=0.89\n",
      "Step 57/63: training loss=1.41, validation loss=0.65\n",
      "Step 58/63: training loss=1.63, validation loss=1.00\n",
      "Step 59/63: training loss=1.73, validation loss=0.76\n",
      "Step 60/63: training loss=1.45, validation loss=0.88, full validation loss=0.68\n",
      "Step 61/63: training loss=1.37, validation loss=1.17\n",
      "Step 62/63: training loss=1.38, validation loss=0.37\n",
      "Step 63/63: training loss=2.43, validation loss=1.00\n",
      "Checkpoint created at step 40 with Snapshot ID: ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-5:9xvYbgrX:ckpt-step-40\n",
      "Checkpoint created at step 60 with Snapshot ID: ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-5:9xvYb7D4:ckpt-step-60\n",
      "New fine-tuned model created: ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-5:9xvYboC9\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=50)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "d0826167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-5:9xvYboC9'"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_l = events[-2].message.split(\" \")\n",
    "ft_model = _l[-1] if _l[-2] == \"created:\" else None\n",
    "ft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "e875bad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their  ...  nature makes  ...  prone to  ...   ...  which further  ...   ...   ...  for a  ...  of applications. However, the  ...  space for  ...  configurations is  ...   ...  the ability to  ...  the properties of  ...  crystals  ...  becomes a vital  ...  In this paper, we focus on predicting the  ...  of such  ...  blended with defects,  ...  and vacancies.  ...   ...  learning  ...  struggle to  ...  the properties of  ...  defects accurately.\n",
      "\n",
      "Their two-dimensional nature makes them prone to chemical modification, which further increases their tunability for a variety of applications. However, the search space for possible configurations is vast. Thus, the ability to predict the properties of such crystals efficiently becomes a vital task. In this paper, we focus on predicting the properties of such crystals blended with defects, substitutions, and vacancies. State-of-the-art machine learning algorithms struggle to learn the properties of crystals’ defects accurately.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Their **intrinsic** nature makes **materials** prone to **defects** **and** which further **complicates** **the** **design** for a **wide range** of applications. However, the **available** space for **configuring** configurations is **limited**, **thus** the ability to **predict** the properties of **defective** crystals **accurately** becomes a vital **challenge**. In this paper, we focus on predicting the **properties** of such **materials** blended with defects, **dislocations**, and vacancies. **Traditional** **machine** learning **models** struggle to **capture** the properties of **complex** defects accurately.'"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j=1\n",
    "test_messages = []\n",
    "test_messages.append({\"role\": \"system\", \n",
    "                      \"content\": data[\"validation\"][j]['messages'][0]['content']})\n",
    "\n",
    "test_messages.append({\"role\": \"user\", \n",
    "                      \"content\": data[\"validation\"][j]['messages'][1]['content']})\n",
    "print(test_messages[1]['content'])\n",
    "print()\n",
    "print(data[\"validation\"][j]['messages'][2]['content'])\n",
    "\n",
    "get_completion(test_messages, ft_model)\n",
    "             #  \"ft:gpt-4o-mini-2024-07-18:constructor-tech:ai4materials-v0-3:9xv8GRrq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46489e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3c966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
